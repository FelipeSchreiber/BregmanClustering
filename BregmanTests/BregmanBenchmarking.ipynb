{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "jP3HrzLaFCl0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jP3HrzLaFCl0",
        "outputId": "a23373f8-1f7f-4dfe-bdee-0d585134fc0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "wqMKN-tSMM0L",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqMKN-tSMM0L",
        "outputId": "10830109-d67f-4ca7-e6c5-4ddc62747f4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/FelipeSchreiber/BregmanClustering.git\n",
            "  Cloning https://github.com/FelipeSchreiber/BregmanClustering.git to /tmp/pip-req-build-ssbua6kl\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/FelipeSchreiber/BregmanClustering.git /tmp/pip-req-build-ssbua6kl\n",
            "  Resolved https://github.com/FelipeSchreiber/BregmanClustering.git to commit 9dad6583eddc22d1c49140961b9dd65a6def5472\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: bregClust\n",
            "  Building wheel for bregClust (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bregClust: filename=bregClust-1.0-py3-none-any.whl size=40523 sha256=b1033050dcead50b7f45e9d49dbf0ef1132008ce61b7dd58b2611923470b7950\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3zeiki4e/wheels/3f/90/fb/833529540c1d5f19c385fde761cc07c664c4b9a5edf7c6735b\n",
            "Successfully built bregClust\n",
            "Installing collected packages: bregClust\n",
            "  Attempting uninstall: bregClust\n",
            "    Found existing installation: bregClust 1.0\n",
            "    Uninstalling bregClust-1.0:\n",
            "      Successfully uninstalled bregClust-1.0\n",
            "Successfully installed bregClust-1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.3.1)\n",
            "Requirement already satisfied: rpy2==3.5.1 in /usr/local/lib/python3.10/dist-packages (3.5.1)\n",
            "Requirement already satisfied: cffi>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from rpy2==3.5.1) (1.15.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from rpy2==3.5.1) (3.1.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from rpy2==3.5.1) (2022.7.1)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from rpy2==3.5.1) (4.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.27.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.10.0->rpy2==3.5.1) (2.21)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->rpy2==3.5.1) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
            "Requirement already satisfied: pytz-deprecation-shim in /usr/local/lib/python3.10/dist-packages (from tzlocal->rpy2==3.5.1) (0.1.0.post0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.10/dist-packages (from pytz-deprecation-shim->tzlocal->rpy2==3.5.1) (2023.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting umap-learn\n",
            "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.2/88.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.10.1)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.56.4)\n",
            "Collecting pynndescent>=0.5 (from umap-learn)\n",
            "  Downloading pynndescent-0.5.10.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from umap-learn) (4.65.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.49->umap-learn) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.49->umap-learn) (67.7.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pynndescent>=0.5->umap-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->umap-learn) (3.1.0)\n",
            "Building wheels for collected packages: umap-learn, pynndescent\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82816 sha256=642887d27b79644fe55c99cd4fc90cb30fea68520d4a4f09e02fd1350fbe60bc\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/e8/c6/a37ea663620bd5200ea1ba0907ab3c217042c1d035ef606acc\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.10-py3-none-any.whl size=55622 sha256=92244ced80dadbe21b87a99ec7717231bf9b7598f15ffe2070cc70e66212230c\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/38/5d/f60a40a66a9512b7e5e83517ebc2d1b42d857be97d135f1096\n",
            "Successfully built umap-learn pynndescent\n",
            "Installing collected packages: pynndescent, umap-learn\n",
            "Successfully installed pynndescent-0.5.10 umap-learn-0.5.3\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall git+https://github.com/FelipeSchreiber/BregmanClustering.git --no-deps\n",
        "!pip install torch_geometric rpy2==3.5.1\n",
        "!pip install umap-learn\n",
        "import os\n",
        "import pickle\n",
        "from sys import platform\n",
        "import BregmanTests\n",
        "os.chmod(BregmanTests.__path__[0]+\"/install_algos.sh\",777)\n",
        "if platform == \"win32\":\n",
        "    os.environ[\"R_HOME\"] = r\"C:\\\\Program Files\\R\\R-4.2.3\"\n",
        "else:\n",
        "    ### Uncomment line below if in Google Colab environment\n",
        "    print(os.path.isfile(BregmanTests.__path__[0]+\"/install_algos.sh\"))\n",
        "    ### Done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4w2gsGfqMbhn",
      "metadata": {
        "id": "4w2gsGfqMbhn"
      },
      "outputs": [],
      "source": [
        "from BregmanTests.benchmark import *\n",
        "n_average = 20\n",
        "n = 600\n",
        "n_clusters = 3\n",
        "d = 1\n",
        "sizes = [ n // n_clusters ]*np.ones( n_clusters, dtype = int )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "break"
      ],
      "metadata": {
        "id": "BRK9Lc7TXYNe",
        "outputId": "5bd47574-40ab-42e1-d31f-8d4c153de12e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "id": "BRK9Lc7TXYNe",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-6aaf1f276005>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test 2_1"
      ],
      "metadata": {
        "id": "4oK8WTsVlLci"
      },
      "id": "4oK8WTsVlLci"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run numpy model"
      ],
      "metadata": {
        "id": "bSqHh5mkgtYf"
      },
      "id": "bSqHh5mkgtYf"
    },
    {
      "cell_type": "code",
      "source": [
        "attributes_distribution = \"gaussian\"\n",
        "edge_distribution = \"bernoulli\"\n",
        "weight_distribution = \"exponential\"\n",
        "a_range = np.linspace(5,14,3)\n",
        "r_range = np.linspace(0,0.7,3)*np.log(n)\n",
        "benchmark = BregmanBenchmark(att_variance=1,\n",
        "                    attributes_distribution=attributes_distribution,\n",
        "                    weight_variance=1,\n",
        "                    weight_distribution=weight_distribution,\n",
        "                    edge_distribution=edge_distribution,\n",
        "                    run_torch=False,\n",
        "                    initializer = 'AIC',\n",
        "                    hard_clustering=True)\n",
        "stats = benchmark.run_2_1(n_average=1,\n",
        "                            cluster_sizes=sizes,\n",
        "                            b=5,\n",
        "                            a_range= a_range,\n",
        "                            r_range = r_range,\n",
        "                            dense=False,\n",
        "                            binary=True,\n",
        "                            strategy = 3,\n",
        "                            n_iters=25)\n",
        "with open('test_2_1.pickle', 'wb') as handle:\n",
        "    pickle.dump(stats, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "!cp \"/content/test_2_1.pickle\" \"/content/drive/MyDrive\""
      ],
      "metadata": {
        "id": "v4iSOddDO2qs"
      },
      "id": "v4iSOddDO2qs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run torch model"
      ],
      "metadata": {
        "id": "w_rMJxzygfZl"
      },
      "id": "w_rMJxzygfZl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1QGRHlHVMvL4",
      "metadata": {
        "id": "1QGRHlHVMvL4"
      },
      "outputs": [],
      "source": [
        "attributes_distribution = \"gaussian\"\n",
        "edge_distribution = \"bernoulli\"\n",
        "weight_distribution = \"exponential\"\n",
        "a_range = np.linspace(5,14,3)\n",
        "r_range = np.linspace(0,0.7,3)*np.log(n)\n",
        "stats = BregmanBenchmark(att_variance=1,\n",
        "                    attributes_distribution=attributes_distribution,\n",
        "                    weight_variance=1,\n",
        "                    weight_distribution=weight_distribution,\n",
        "                    edge_distribution=edge_distribution,\n",
        "                    run_torch=True,\n",
        "                    initializer = 'chernoff')\\\n",
        "                  .run_2_1(n_average=1,\n",
        "                            cluster_sizes=sizes,\n",
        "                            b=5,\n",
        "                            a_range= a_range,\n",
        "                            r_range = r_range,\n",
        "                            dense=False,\n",
        "                            binary=True)\n",
        "with open('test_2_1.pickle', 'wb') as handle:\n",
        "    pickle.dump(stats, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "!cp \"/content/test_2_1.pickle\" \"/content/drive/MyDrive\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test 2_2"
      ],
      "metadata": {
        "id": "VVVPpsn8l01D"
      },
      "id": "VVVPpsn8l01D"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XYNgyTRXEhrK",
      "metadata": {
        "id": "XYNgyTRXEhrK"
      },
      "outputs": [],
      "source": [
        "attributes_distribution = \"poisson\"\n",
        "edge_distribution = \"bernoulli\"\n",
        "weight_distribution = \"gaussian\"\n",
        "d_range = np.arange(1,6)\n",
        "mu_range = np.linspace(0,6,20)\n",
        "att_centers = np.arange(1,4).reshape(-1,1)\n",
        "stats = BregmanBenchmark(att_variance=1,\n",
        "                    attributes_distribution=attributes_distribution,\n",
        "                    weight_variance=1,\n",
        "                    weight_distribution=weight_distribution,\n",
        "                    edge_distribution=edge_distribution,\n",
        "                    att_centers=att_centers,\n",
        "                    run_torch=False\n",
        "                  )\\\n",
        "                  .run_2_2(n_average=10,\n",
        "                            cluster_sizes=sizes,\n",
        "                             d_range = d_range,\n",
        "                             mu_range = mu_range,\n",
        "                             dense=True,\n",
        "                             binary=False)\n",
        "with open('test_2_2.pickle', 'wb') as handle:\n",
        "    pickle.dump(stats, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "!cp \"/content/test_2_2.pickle\" \"/content/drive/MyDrive\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test 2_3"
      ],
      "metadata": {
        "id": "XlpxvjqBlt3q"
      },
      "id": "XlpxvjqBlt3q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GdUwRBlstRH-",
      "metadata": {
        "id": "GdUwRBlstRH-"
      },
      "outputs": [],
      "source": [
        "attributes_distribution = \"poisson\"\n",
        "edge_distribution = \"bernoulli\"\n",
        "weight_distribution = \"exponential\"\n",
        "d_range = np.arange(1,5)\n",
        "a_range = np.linspace(5,14,10)\n",
        "lambda_range = np.arange(1,6)\n",
        "att_centers = np.arange(1,4).reshape(-1,1)\n",
        "stats = BregmanBenchmark(att_variance=1,\n",
        "                    attributes_distribution=attributes_distribution,\n",
        "                    weight_variance=1,\n",
        "                    weight_distribution=weight_distribution,\n",
        "                    edge_distribution=edge_distribution,\n",
        "                    att_centers=att_centers,\n",
        "                    run_torch=False\n",
        "                 )\\\n",
        "                  .run_2_3(n_average=10,\n",
        "                            cluster_sizes=sizes,\n",
        "                            d_range= d_range,\n",
        "                            lambda_range = lambda_range,\n",
        "                            a_range = a_range,\n",
        "                            b = 5,\n",
        "                            dense=False,\n",
        "                            binary=False)\n",
        "with open('test_2_3.pickle', 'wb') as handle:\n",
        "    pickle.dump(stats, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "!cp \"/content/test_2_3.pickle\" \"/content/drive/MyDrive\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test 2_4"
      ],
      "metadata": {
        "id": "HcYf4xKeleyK"
      },
      "id": "HcYf4xKeleyK"
    },
    {
      "cell_type": "code",
      "source": [
        "attributes_distribution = \"exponential\"\n",
        "edge_distribution = \"bernoulli\"\n",
        "weight_distribution = \"exponential\"\n",
        "att_averages = np.linspace(1,5,10)\n",
        "w_averages = np.linspace(1,5,10)\n",
        "stats = BregmanBenchmark(att_variance=1,\n",
        "                    attributes_distribution=attributes_distribution,\n",
        "                    weight_variance=1,\n",
        "                    weight_distribution=weight_distribution,\n",
        "                    edge_distribution=edge_distribution,\n",
        "                    run_torch=False\n",
        "                 )\\\n",
        "                  .run_2_4(n_average=10,\n",
        "                            cluster_sizes=sizes,\n",
        "                            b = 5,\n",
        "                            w_averages=w_averages,\n",
        "                            att_averages=att_averages)\n",
        "with open('test_2_4.pickle', 'wb') as handle:\n",
        "    pickle.dump(stats, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "!cp \"/content/test_2_4.pickle\" \"/content/drive/MyDrive\""
      ],
      "metadata": {
        "id": "isj4xK4sGdg9"
      },
      "id": "isj4xK4sGdg9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test 2_5"
      ],
      "metadata": {
        "id": "JWvoW4tklTOT"
      },
      "id": "JWvoW4tklTOT"
    },
    {
      "cell_type": "code",
      "source": [
        "attributes_distribution = \"exponential\"\n",
        "edge_distribution = \"bernoulli\"\n",
        "weight_distribution = \"exponential\"\n",
        "att_averages = np.linspace(1,5,5)\n",
        "w_averages = np.array([1,3,6,9,12])\n",
        "stats = BregmanBenchmark(att_variance=n_average,\n",
        "                    attributes_distribution=attributes_distribution,\n",
        "                    weight_variance=1,\n",
        "                    weight_distribution=weight_distribution,\n",
        "                    edge_distribution=edge_distribution,\n",
        "                    run_torch=False\n",
        "                 )\\\n",
        "                  .run_2_5(n_average=n_average,\n",
        "                            cluster_sizes=sizes,\n",
        "                            b = 5,\n",
        "                            w_averages=w_averages,\n",
        "                            att_averages=att_averages)\n",
        "with open('test_2_5.pickle', 'wb') as handle:\n",
        "    pickle.dump(stats, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "!cp \"/content/test_2_5.pickle\" \"/content/drive/MyDrive\""
      ],
      "metadata": {
        "id": "Zpr5g5JCzEkG"
      },
      "id": "Zpr5g5JCzEkG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_2_5=None\n",
        "with open(\"/content/drive/MyDrive/test_2_5.pickle\", 'rb') as handle:\n",
        "    test_2_5 = pickle.load(handle)\n",
        "test_2_5.keys()\n",
        "df = pd.DataFrame.from_dict(test_2_5)\n",
        "# labels = [ 'EM-GMM', 'SC', 'Algo1', 'attSBM','IR_sLS']\n",
        "# algos = [\"attributes\", \"graph\", \"ours\", \"attSBM\", \"IR_sLS\"]\n",
        "# saveFig = True\n",
        "# for varying in [\"graph\",\"attributes\"]:\n",
        "#   curves = []\n",
        "#   curves_std = []\n",
        "#   for algo in algos:\n",
        "#     curves.append(df.loc[(df['varying'] == varying) & (df['algorithm'] == algo)][\"ARI\"])\n",
        "#     curves_std.append(df.loc[(df['varying'] == varying) & (df['algorithm'] == algo)][\"ARI_std\"])\n",
        "#   if varying == 'graph':\n",
        "#     x = df.loc[(df['varying'] == \"graph\")][\"weights_avg\"].unique()\n",
        "#     fileName = 'N_' + str(n) + '_K_' + str(n_clusters) + '_att_' + str(2)  +  '_nAverage' + str(n_average) + '.jpeg'\n",
        "#     plotting( x, curves, labels, curves_std = curves_std, xticks = x, xlabel = 'weights_avg', saveFig = True, fileName = fileName )\n",
        "#     plt.close()\n",
        "#   elif varying == 'attributes':\n",
        "#     x = df.loc[(df['varying'] == \"attributes\")][\"attributes_avg\"].unique()\n",
        "#     fileName = 'N_' + str(n) + '_K_' + str(n_clusters) + '_w_' + str(2) + '_nAverage_' + str(n_average) + '.jpeg'\n",
        "#     plotting( x , curves, labels, curves_std = curves_std, xticks = x, xlabel = 'attributes_avg', saveFig = True, fileName = fileName )\n",
        "#     plt.close()"
      ],
      "metadata": {
        "id": "HROKJI17kQ-y"
      },
      "id": "HROKJI17kQ-y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Real Data"
      ],
      "metadata": {
        "id": "BCvSIxvhmD5j"
      },
      "id": "BCvSIxvhmD5j"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7942ed30",
      "metadata": {
        "id": "7942ed30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75dc02d4-d4a6-4b5d-d982-1199d5ee8c40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CURRENT DATASET:  Cornell\n",
            "INPUTS:  (183, 183) (183, 183, 1) torch.Size([183, 10])\n",
            "\n",
            "CURRENT DATASET:  Texas\n",
            "INPUTS:  (183, 183) (183, 183, 1) torch.Size([183, 10])\n",
            "\n",
            "CURRENT DATASET:  Wisconsin\n",
            "INPUTS:  (251, 251) (251, 251, 1) torch.Size([251, 10])\n",
            "\n",
            "CURRENT DATASET:  Cora\n",
            "INPUTS:  (2708, 2708) (2708, 2708, 1) torch.Size([2708, 10])\n",
            "\n",
            "CURRENT DATASET:  CiteSeer\n",
            "INPUTS:  (3327, 3327) (3327, 3327, 1) torch.Size([3327, 10])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dataset': ['Cornell', 'Texas', 'Wisconsin', 'Cora', 'CiteSeer'],\n",
              " 'both_ARI': [0.016578801177917813,\n",
              "  0.06092552371796141,\n",
              "  0.056435362009954505,\n",
              "  0.24244886989875844,\n",
              "  0.011328510022817479],\n",
              " 'net_ARI': [0.013962337228188881,\n",
              "  0.03409908262242319,\n",
              "  0.03511484798412808,\n",
              "  -0.0032552936119657028,\n",
              "  0.0207029867320557],\n",
              " 'att_ARI': [0.21720286576852185,\n",
              "  0.1266870719837932,\n",
              "  0.14273384359454355,\n",
              "  0.11834507301834235,\n",
              "  0.00041476158345146085]}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "attributes_distribution = \"gaussian\"\n",
        "edge_distribution = \"bernoulli\"\n",
        "weight_distribution = \"gaussian\"\n",
        "benchmark = BregmanBenchmark(att_variance=1,\n",
        "                    attributes_distribution=attributes_distribution,\n",
        "                    weight_variance=1,\n",
        "                    weight_distribution=weight_distribution,\n",
        "                    edge_distribution=edge_distribution,\n",
        "                    run_torch=False,\n",
        "                    initializer = 'AIC',\n",
        "                    hard_clustering=True)\n",
        "scores = benchmark.run_real_data(strategy=3,n_iters=100,reduction_method=\"UMAP\")\n",
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(scores)"
      ],
      "metadata": {
        "id": "qEpRHoNLQeqd",
        "outputId": "ff8a04ef-034c-4a63-c03c-8334bc03ef29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "id": "qEpRHoNLQeqd",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     dataset  both_ARI   net_ARI   att_ARI\n",
              "0    Cornell  0.016579  0.013962  0.217203\n",
              "1      Texas  0.060926  0.034099  0.126687\n",
              "2  Wisconsin  0.056435  0.035115  0.142734\n",
              "3       Cora  0.242449 -0.003255  0.118345\n",
              "4   CiteSeer  0.011329  0.020703  0.000415"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-97b413c6-30b4-4324-a3fb-a4d9f27cc14e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>both_ARI</th>\n",
              "      <th>net_ARI</th>\n",
              "      <th>att_ARI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cornell</td>\n",
              "      <td>0.016579</td>\n",
              "      <td>0.013962</td>\n",
              "      <td>0.217203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Texas</td>\n",
              "      <td>0.060926</td>\n",
              "      <td>0.034099</td>\n",
              "      <td>0.126687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Wisconsin</td>\n",
              "      <td>0.056435</td>\n",
              "      <td>0.035115</td>\n",
              "      <td>0.142734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cora</td>\n",
              "      <td>0.242449</td>\n",
              "      <td>-0.003255</td>\n",
              "      <td>0.118345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CiteSeer</td>\n",
              "      <td>0.011329</td>\n",
              "      <td>0.020703</td>\n",
              "      <td>0.000415</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97b413c6-30b4-4324-a3fb-a4d9f27cc14e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-97b413c6-30b4-4324-a3fb-a4d9f27cc14e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-97b413c6-30b4-4324-a3fb-a4d9f27cc14e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Using strategy 3:\n",
        "\n",
        "25 runs\n",
        "{'dataset': ['Cornell', 'Texas', 'Wisconsin', 'Cora', 'CiteSeer'],\n",
        " 'ARI': [0.021333077187108966,\n",
        "  0.02158094558247706,\n",
        "  0.06561886114111304,\n",
        "  0.09454483715306834,\n",
        "  0.021826025060071436]}\n",
        "\n",
        "100 runs\n",
        "{'dataset': ['Cornell', 'Texas', 'Wisconsin', 'Cora', 'CiteSeer'],\n",
        " 'ARI': [-0.00813056323456639,\n",
        "  0.020549452476684223,\n",
        "  0.06253016110148793,\n",
        "  0.174525709285103,\n",
        "  0.022005394987926818]}\n",
        "\n",
        "Using strategy 0:\n",
        "\n",
        "25runs\n",
        "{'dataset': ['Cornell', 'Texas', 'Wisconsin', 'Cora', 'CiteSeer'],\n",
        " 'ARI': [0.0020494127978944623,\n",
        "  0.021389147279564147,\n",
        "  0.04300891147648944,\n",
        "  -0.00330201159364617,\n",
        "  0.25845609477298936]}\n",
        "\n",
        "100 runs\n",
        "{'dataset': ['Cornell', 'Texas', 'Wisconsin', 'Cora', 'CiteSeer'],\n",
        " 'ARI': [0.008127656067387532,\n",
        "  0.023515852562689822,\n",
        "  0.06482587767403367,\n",
        "  0.0248570289631233,\n",
        "  0.021949234040387094]}\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "9StId__H-ZD0"
      },
      "id": "9StId__H-ZD0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UJ_dbuJWeAn8",
      "metadata": {
        "id": "UJ_dbuJWeAn8"
      },
      "outputs": [],
      "source": [
        "# attributes_distribution = \"gaussian\"\n",
        "# edge_distribution = \"bernoulli\"\n",
        "# weight_distribution = \"exponential\"\n",
        "# BregmanBenchmark(att_variance=1,\n",
        "#                     attributes_distribution=attributes_distribution,\n",
        "#                     weight_variance=1,\n",
        "#                     weight_distribution=weight_distribution,\n",
        "#                     edge_distribution=edge_distribution,\n",
        "#                     run_torch=False)\\\n",
        "#                  .run_test(n_average=n_average,cluster_sizes=sizes,\\\n",
        "#                  b=5,\\\n",
        "#                  a_range=[ 5,7,9,11,13,15 ],\\\n",
        "#                  r_range = [ 0,1,2,3,4,5 ],\\\n",
        "#                  dense=False,\\\n",
        "#                  binary=True,\\\n",
        "#                  file_endings=\".jpeg\",\\\n",
        "#                  n_iters=25)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Begin Plots"
      ],
      "metadata": {
        "id": "7rU3bGnAmO8n"
      },
      "id": "7rU3bGnAmO8n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f1ZvaasK7XH",
      "metadata": {
        "id": "8f1ZvaasK7XH"
      },
      "outputs": [],
      "source": [
        "from BregmanTests.utils import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3vN0pwvtM-Eo",
      "metadata": {
        "id": "3vN0pwvtM-Eo"
      },
      "outputs": [],
      "source": [
        "test_2_1=None\n",
        "with open(\"/content/drive/MyDrive/test_2_1.pickle\", 'rb') as handle:\n",
        "    test_2_1 = pickle.load(handle)\n",
        "test_2_1.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TrkQZoOAQae4",
      "metadata": {
        "id": "TrkQZoOAQae4"
      },
      "outputs": [],
      "source": [
        "scatter_(test_2_1,'a', 'r', 'ARI')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QY5bJiRenKe8",
      "metadata": {
        "id": "QY5bJiRenKe8"
      },
      "outputs": [],
      "source": [
        "scatter_with_colorbar(test_2_1,'a', 'r', 'ARI')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_2_4=None\n",
        "SIZE_TITLE = 24\n",
        "SIZE_LABELS = 24\n",
        "SIZE_TICKS = 18\n",
        "SIZE_LEGEND = 18\n",
        "with open(\"/content/drive/MyDrive/test_2_4.pickle\", 'rb') as handle:\n",
        "    test_2_4 = pickle.load(handle)\n",
        "fig = plt.figure(figsize=(5, 4))\n",
        "ax = fig.add_subplot(111)\n",
        "x,y,z = np.array(test_2_4[\"lambda_att\"]),np.array(test_2_4[\"lambda_w\"]),np.array(test_2_4[\"ARI\"])\n",
        "xlabel=\"attributes_avg\"\n",
        "ylabel=\"weights_avg\"\n",
        "C = ax.scatter(x=1/x,y=1/y,c=z,cmap=\"coolwarm\")\n",
        "plt.ylim(0.9,3.5)\n",
        "ticks = np.linspace(z.min(), z.max(), 5, endpoint=True)\n",
        "cb = fig.colorbar(C, ax=ax, fraction=0.02, pad=0.1, label='ARI',ticks=ticks)\n",
        "cb.set_label(label='ARI', size=SIZE_LEGEND)\n",
        "cb.ax.tick_params(labelsize=SIZE_TICKS)\n",
        "plt.xlabel( xlabel, fontsize = SIZE_LABELS )\n",
        "plt.ylabel( ylabel, fontsize = SIZE_LABELS )\n",
        "plt.xticks( fontsize = SIZE_TICKS )\n",
        "plt.yticks( fontsize = SIZE_TICKS )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wBuJ9YmNZqUu"
      },
      "id": "wBuJ9YmNZqUu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B8LRjwn2N3ja",
      "metadata": {
        "id": "B8LRjwn2N3ja"
      },
      "outputs": [],
      "source": [
        "x,y,z = test_2_1[\"a\"],test_2_1[\"r\"],test_2_1[\"ARI\"]\n",
        "vals_x = np.unique(x)\n",
        "vals_y = np.unique(y)\n",
        "\"\"\"\n",
        "len(X) == N is the number of columns in Z and len(Y) == M is the number of rows in Z.\n",
        "Z = M x N\n",
        "\"\"\"\n",
        "x = np.array(x).reshape(vals_x.shape[0],vals_y.shape[0])\n",
        "y = np.array(y).reshape(vals_x.shape[0],vals_y.shape[0])\n",
        "z = np.array(z).reshape(vals_x.shape[0],vals_y.shape[0]).T\n",
        "make_contour_plot(vals_x,vals_y,z,x_label=\"a\",y_label=\"r\",filename=\"contour_plot_2_1.jpeg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GzYD-jJYV6h4",
      "metadata": {
        "id": "GzYD-jJYV6h4"
      },
      "outputs": [],
      "source": [
        "test_2_2=None\n",
        "with open(\"/content/drive/MyDrive/test_2_2.pickle\", 'rb') as handle:\n",
        "    test_2_2 = pickle.load(handle)\n",
        "test_2_2.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OF2FxOgcV9Fp",
      "metadata": {
        "id": "OF2FxOgcV9Fp"
      },
      "outputs": [],
      "source": [
        "scatter_(test_2_2,'d', 'mu', 'ARI')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HcgfbcQMYA7-",
      "metadata": {
        "id": "HcgfbcQMYA7-"
      },
      "outputs": [],
      "source": [
        "x,y,z = test_2_2[\"d\"],test_2_2[\"mu\"],test_2_2[\"ARI\"]\n",
        "vals_x = np.unique(x)\n",
        "vals_y = np.unique(y)\n",
        "\"\"\"\n",
        "len(X) == N is the number of columns in Z and len(Y) == M is the number of rows in Z.\n",
        "Z = M x N\n",
        "\"\"\"\n",
        "x = np.array(x).reshape(vals_x.shape[0],vals_y.shape[0])\n",
        "y = np.array(y).reshape(vals_x.shape[0],vals_y.shape[0])\n",
        "# x,y = np.meshgrid(vals_x,vals_y)\n",
        "z = np.array(z).reshape(len(vals_x),len(vals_y)).T\n",
        "make_contour_plot(vals_x,vals_y,z,x_label=\"d\",y_label=\"mu\",filename=\"contour_plot_2_2.jpeg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tKwys6pKYU31",
      "metadata": {
        "id": "tKwys6pKYU31"
      },
      "outputs": [],
      "source": [
        "test_2_3=None\n",
        "with open(\"/content/drive/MyDrive/test_2_3.pickle\", 'rb') as handle:\n",
        "    test_2_3 = pickle.load(handle)\n",
        "test_2_3.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1Dk3He9t3kkn",
      "metadata": {
        "id": "1Dk3He9t3kkn"
      },
      "outputs": [],
      "source": [
        "x,y,z,data = test_2_3[\"d\"],test_2_3[\"lambda\"], test_2_3[\"a\"],test_2_3[\"ARI\"]\n",
        "vals_x = np.unique(x)\n",
        "vals_y = np.unique(y)\n",
        "vals_z = np.unique(z)\n",
        "\"\"\"\n",
        "len(X) == N is the number of columns in data,\n",
        "len(Y) == M is the number of rows in data.\n",
        "len(Z) == P is the depth of data\n",
        "DATA = M x N X P\n",
        "\"\"\"\n",
        "X = np.array(x).reshape(vals_x.shape[0],vals_y.shape[0],vals_z.shape[0])\n",
        "Y = np.array(y).reshape(vals_x.shape[0],vals_y.shape[0],vals_z.shape[0])\n",
        "Z = np.array(z).reshape(vals_x.shape[0],vals_y.shape[0],vals_z.shape[0])\n",
        "data = np.array(data).reshape(vals_x.shape[0],vals_y.shape[0],vals_z.shape[0])\n",
        "x_label=\"d\"\n",
        "y_label=\"lambda\"\n",
        "z_label = \"a\"\n",
        "\n",
        "kw = {\n",
        "        # 'vmin': data.min(),\n",
        "        # 'vmax': data.max()\n",
        "    }\n",
        "\n",
        "# Create a figure with 3D ax\n",
        "fig = plt.figure(figsize=(5, 4))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Set limits of the plot from coord limits\n",
        "xmin, xmax = X.min(), X.max()\n",
        "ymin, ymax = Y.min(), Y.max()\n",
        "zmin, zmax = Z.min(), Z.max()\n",
        "ax.set(xlim=[xmin, xmax], ylim=[ymin, ymax], zlim=[zmin, zmax])\n",
        "\n",
        "# Plot contour surfaces\n",
        "    ### This is the X x Y plane for z=zmax\n",
        "_ = ax.contourf(\n",
        "            X[:, :, -1], Y[:, :, -1], data[:, :, -1],\n",
        "            zdir='z', offset=zmax, **kw\n",
        "        )\n",
        "\n",
        "    ### This is the X x Y plane for z=zmin\n",
        "_ = ax.contourf(\n",
        "            X[:, :, 0], Y[:, :, 0], data[:, :, 0],\n",
        "            zdir='z', offset=zmin, **kw\n",
        "        )\n",
        "\n",
        "    ### This is the X x Z plane for y=ymax\n",
        "_ = ax.contourf(\n",
        "            X[-1, :, :], data[-1, :, :], Z[-1, :, :],\n",
        "            zdir='y', offset=ymax, **kw\n",
        "        )\n",
        "\n",
        "    ### This is the X x Z plane for y=ymin\n",
        "_ = ax.contourf(\n",
        "            X[0, :, :], data[0, :, :], Z[0, :, :],\n",
        "            zdir='y', offset=ymin, **kw\n",
        "        )\n",
        "\n",
        "    ### This is the Y x Z plane for x=xmax\n",
        "_ = ax.contourf(\n",
        "            data[:, -1, :], Y[:, -1, :], Z[:, -1, :],\n",
        "            zdir='x', offset=xmax, **kw\n",
        "        )\n",
        "\n",
        "    ### This is the Y x Z plane for x=xmin\n",
        "C = ax.contourf(\n",
        "            data[:, 0, :], Y[:, 0, :], Z[:, 0, :],\n",
        "            zdir='x', offset=xmin, **kw\n",
        "        )\n",
        "\n",
        "\n",
        "# Plot edges\n",
        "edges_kw = dict(color='0.4', linewidth=1,zorder=-1e3)\n",
        "ax.plot([xmax, xmax], [ymin, ymax], zmin, **edges_kw)\n",
        "ax.plot([xmin, xmax], [ymin, ymin], zmin, **edges_kw)\n",
        "ax.plot([xmin, xmax], [ymin, ymin], [zmin, zmax], **edges_kw)\n",
        "\n",
        "# Set labels and zticks\n",
        "ax.set(\n",
        "        xlabel=x_label,\n",
        "        ylabel=y_label,\n",
        "        zlabel=z_label\n",
        "    )\n",
        "\n",
        "# Set zoom and angle view\n",
        "ax.view_init(30, 45, 0)\n",
        "ax.set_box_aspect(None, zoom=0.9)\n",
        "\n",
        "# Colorbar\n",
        "fig.colorbar(C, ax=ax, fraction=0.02, pad=0.1, label='ARI')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "N2yOg0zK6osd",
      "metadata": {
        "id": "N2yOg0zK6osd"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(5, 4))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.set(\n",
        "        xlabel=x_label,\n",
        "        ylabel=y_label,\n",
        "        zlabel=z_label\n",
        "    )\n",
        "C = ax.scatter(xs=X,ys=Y,zs=Z,c=data)\n",
        "fig.colorbar(C, ax=ax, fraction=0.02, pad=0.2, label='ARI')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}