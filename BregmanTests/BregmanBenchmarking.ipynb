{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "jP3HrzLaFCl0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jP3HrzLaFCl0",
        "outputId": "c127e4b6-5492-4a5a-c0cf-36325d0ddf6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wqMKN-tSMM0L",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqMKN-tSMM0L",
        "outputId": "6cf83b31-7b61-40ba-b2e4-9266005b5021"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.3.1)\n",
            "Requirement already satisfied: rpy2==3.5.1 in /usr/local/lib/python3.10/dist-packages (3.5.1)\n",
            "Requirement already satisfied: cffi>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from rpy2==3.5.1) (1.15.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from rpy2==3.5.1) (3.1.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from rpy2==3.5.1) (2022.7.1)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from rpy2==3.5.1) (5.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.10.0->rpy2==3.5.1) (2.21)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->rpy2==3.5.1) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.5.7)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.10/dist-packages (0.5.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.10.1)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.56.4)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.5.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from umap-learn) (4.65.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.49->umap-learn) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.49->umap-learn) (67.7.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pynndescent>=0.5->umap-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->umap-learn) (3.1.0)\n",
            "Requirement already satisfied: igraph in /usr/local/lib/python3.10/dist-packages (0.10.5)\n",
            "Requirement already satisfied: texttable>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from igraph) (1.6.7)\n",
            "Requirement already satisfied: find-julia in /usr/local/lib/python3.10/dist-packages (0.2.9)\n",
            "Requirement already satisfied: julia-semver in /usr/local/lib/python3.10/dist-packages (from find-julia) (0.1.3)\n",
            "Requirement already satisfied: jill in /usr/local/lib/python3.10/dist-packages (from find-julia) (0.11.3)\n",
            "Requirement already satisfied: fire<0.6.0,>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from jill->find-julia) (0.5.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.17.3 in /usr/local/lib/python3.10/dist-packages (from jill->find-julia) (4.17.3)\n",
            "Requirement already satisfied: python-gnupg<0.6.0,>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from jill->find-julia) (0.5.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.2 in /usr/local/lib/python3.10/dist-packages (from jill->find-julia) (2.31.0)\n",
            "Requirement already satisfied: requests-futures<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from jill->find-julia) (1.0.1)\n",
            "Requirement already satisfied: semantic-version<3.0.0,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from jill->find-julia) (2.10.0)\n",
            "Requirement already satisfied: wget<4.0,>=3.2 in /usr/local/lib/python3.10/dist-packages (from jill->find-julia) (3.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire<0.6.0,>=0.5.0->jill->find-julia) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire<0.6.0,>=0.5.0->jill->find-julia) (2.3.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.17.3->jill->find-julia) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.17.3->jill->find-julia) (0.19.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.28.2->jill->find-julia) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.28.2->jill->find-julia) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.28.2->jill->find-julia) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.28.2->jill->find-julia) (2023.5.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric rpy2==3.5.1\n",
        "!pip install umap-learn\n",
        "!pip install igraph\n",
        "!pip install find-julia\n",
        "!wget https://julialang-s3.julialang.org/bin/linux/x64/1.8/julia-1.8.1-linux-x86_64.tar.gz\n",
        "!tar zxvf julia-1.8.1-linux-x86_64.tar.gz -C /usr/local --strip-components 1\n",
        "!pip install --upgrade --force-reinstall git+https://github.com/FelipeSchreiber/BregmanClustering.git --no-deps\n",
        "!pip install leidenalg\n",
        "import os\n",
        "import pickle\n",
        "from sys import platform\n",
        "import BregmanTests\n",
        "os.chmod(BregmanTests.__path__[0]+\"/install_algos.sh\",777)\n",
        "if platform == \"win32\":\n",
        "    os.environ[\"R_HOME\"] = r\"C:\\\\Program Files\\R\\R-4.2.3\"\n",
        "else:\n",
        "    ### Uncomment line below if in Google Colab environment\n",
        "    print(os.path.isfile(BregmanTests.__path__[0]+\"/install_algos.sh\"))\n",
        "    ### Done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4w2gsGfqMbhn",
      "metadata": {
        "id": "4w2gsGfqMbhn"
      },
      "outputs": [],
      "source": [
        "from BregmanTests.benchmark import *\n",
        "n_average = 20\n",
        "n = 600\n",
        "n_clusters = 3\n",
        "d = 1\n",
        "sizes = [ n // n_clusters ]*np.ones( n_clusters, dtype = int )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "break"
      ],
      "metadata": {
        "id": "P7eaRWHE-d8H"
      },
      "id": "P7eaRWHE-d8H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attributes_distribution = \"gaussian\"\n",
        "edge_distribution = \"bernoulli\"\n",
        "weight_distribution = \"exponential\"\n",
        "a_range = np.linspace(5,14,3)\n",
        "r_range = np.linspace(0,0.7,3)*np.log(n)\n",
        "benchmark = BregmanBenchmark(att_variance=1,\n",
        "                    attributes_distribution=attributes_distribution,\n",
        "                    weight_variance=1,\n",
        "                    weight_distribution=weight_distribution,\n",
        "                    edge_distribution=edge_distribution,\n",
        "                    run_torch=True,\n",
        "                    initializer = 'chernoff',\n",
        "                    hard_clustering=True)\n",
        "benchmark.run_test(n_average=1,cluster_sizes=sizes,\\\n",
        "                 b=5,\\\n",
        "                 a_range=[ 5,7,9,11,13,15 ],\\\n",
        "                 r_range = [ 0,1,2,3,4,5 ],\\\n",
        "                 dense=False,\\\n",
        "                 binary=True,\\\n",
        "                 file_endings=\".jpeg\",\\\n",
        "                 n_iters=25)"
      ],
      "metadata": {
        "id": "BRK9Lc7TXYNe"
      },
      "id": "BRK9Lc7TXYNe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test 2_1"
      ],
      "metadata": {
        "id": "4oK8WTsVlLci"
      },
      "id": "4oK8WTsVlLci"
    },
    {
      "cell_type": "code",
      "source": [
        "attributes_distribution = \"gaussian\"\n",
        "edge_distribution = \"bernoulli\"\n",
        "weight_distribution = \"exponential\"\n",
        "a_range = np.linspace(5,14,3)\n",
        "r_range = np.linspace(0,0.7,3)*np.log(n)\n",
        "benchmark = BregmanBenchmark(att_variance=1,\n",
        "                    attributes_distribution=attributes_distribution,\n",
        "                    weight_variance=1,\n",
        "                    weight_distribution=weight_distribution,\n",
        "                    edge_distribution=edge_distribution,\n",
        "                    run_torch=False,\n",
        "                    initializer = 'chernoff',\n",
        "                    hard_clustering=False)\n",
        "stats = benchmark.run_2_1(n_average=1,\n",
        "                            cluster_sizes=sizes,\n",
        "                            b=5,\n",
        "                            a_range= a_range,\n",
        "                            r_range = r_range,\n",
        "                            dense=False,\n",
        "                            binary=True,\n",
        "                            n_iters=25)\n",
        "with open('test_2_1.pickle', 'wb') as handle:\n",
        "    pickle.dump(stats, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "!cp \"/content/test_2_1.pickle\" \"/content/drive/MyDrive\""
      ],
      "metadata": {
        "id": "v4iSOddDO2qs"
      },
      "id": "v4iSOddDO2qs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test 2_2"
      ],
      "metadata": {
        "id": "VVVPpsn8l01D"
      },
      "id": "VVVPpsn8l01D"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XYNgyTRXEhrK",
      "metadata": {
        "id": "XYNgyTRXEhrK"
      },
      "outputs": [],
      "source": [
        "attributes_distribution = \"poisson\"\n",
        "edge_distribution = \"bernoulli\"\n",
        "weight_distribution = \"gaussian\"\n",
        "d_range = np.arange(1,6)\n",
        "mu_range = np.linspace(0,6,20)\n",
        "att_centers = np.arange(1,4).reshape(-1,1)\n",
        "stats = BregmanBenchmark(att_variance=1,\n",
        "                    attributes_distribution=attributes_distribution,\n",
        "                    weight_variance=1,\n",
        "                    weight_distribution=weight_distribution,\n",
        "                    edge_distribution=edge_distribution,\n",
        "                    att_centers=att_centers,\n",
        "                    run_torch=False\n",
        "                  )\\\n",
        "                  .run_2_2(n_average=10,\n",
        "                            cluster_sizes=sizes,\n",
        "                             d_range = d_range,\n",
        "                             mu_range = mu_range,\n",
        "                             dense=True,\n",
        "                             binary=False)\n",
        "with open('test_2_2.pickle', 'wb') as handle:\n",
        "    pickle.dump(stats, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "!cp \"/content/test_2_2.pickle\" \"/content/drive/MyDrive\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test 2_3"
      ],
      "metadata": {
        "id": "XlpxvjqBlt3q"
      },
      "id": "XlpxvjqBlt3q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GdUwRBlstRH-",
      "metadata": {
        "id": "GdUwRBlstRH-"
      },
      "outputs": [],
      "source": [
        "attributes_distribution = \"poisson\"\n",
        "edge_distribution = \"bernoulli\"\n",
        "weight_distribution = \"exponential\"\n",
        "d_range = np.arange(1,5)\n",
        "a_range = np.linspace(5,14,10)\n",
        "lambda_range = np.arange(1,6)\n",
        "att_centers = np.arange(1,4).reshape(-1,1)\n",
        "stats = BregmanBenchmark(att_variance=1,\n",
        "                    attributes_distribution=attributes_distribution,\n",
        "                    weight_variance=1,\n",
        "                    weight_distribution=weight_distribution,\n",
        "                    edge_distribution=edge_distribution,\n",
        "                    att_centers=att_centers,\n",
        "                    run_torch=False\n",
        "                 )\\\n",
        "                  .run_2_3(n_average=10,\n",
        "                            cluster_sizes=sizes,\n",
        "                            d_range= d_range,\n",
        "                            lambda_range = lambda_range,\n",
        "                            a_range = a_range,\n",
        "                            b = 5,\n",
        "                            dense=False,\n",
        "                            binary=False)\n",
        "with open('test_2_3.pickle', 'wb') as handle:\n",
        "    pickle.dump(stats, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "!cp \"/content/test_2_3.pickle\" \"/content/drive/MyDrive\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test 2_4"
      ],
      "metadata": {
        "id": "HcYf4xKeleyK"
      },
      "id": "HcYf4xKeleyK"
    },
    {
      "cell_type": "code",
      "source": [
        "attributes_distribution = \"exponential\"\n",
        "edge_distribution = \"bernoulli\"\n",
        "weight_distribution = \"exponential\"\n",
        "att_averages = np.linspace(1,5,10)\n",
        "w_averages = np.linspace(1,5,10)\n",
        "stats = BregmanBenchmark(att_variance=1,\n",
        "                    attributes_distribution=attributes_distribution,\n",
        "                    weight_variance=1,\n",
        "                    weight_distribution=weight_distribution,\n",
        "                    edge_distribution=edge_distribution,\n",
        "                    run_torch=False\n",
        "                 )\\\n",
        "                  .run_2_4(n_average=10,\n",
        "                            cluster_sizes=sizes,\n",
        "                            b = 5,\n",
        "                            w_averages=w_averages,\n",
        "                            att_averages=att_averages)\n",
        "with open('test_2_4.pickle', 'wb') as handle:\n",
        "    pickle.dump(stats, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "!cp \"/content/test_2_4.pickle\" \"/content/drive/MyDrive\""
      ],
      "metadata": {
        "id": "isj4xK4sGdg9"
      },
      "id": "isj4xK4sGdg9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test 2_5"
      ],
      "metadata": {
        "id": "JWvoW4tklTOT"
      },
      "id": "JWvoW4tklTOT"
    },
    {
      "cell_type": "code",
      "source": [
        "attributes_distribution = \"exponential\"\n",
        "edge_distribution = \"bernoulli\"\n",
        "weight_distribution = \"exponential\"\n",
        "att_averages = np.linspace(1,5,5)\n",
        "w_averages = np.array([1,3,6,9,12])\n",
        "stats = BregmanBenchmark(att_variance=n_average,\n",
        "                    attributes_distribution=attributes_distribution,\n",
        "                    weight_variance=1,\n",
        "                    weight_distribution=weight_distribution,\n",
        "                    edge_distribution=edge_distribution,\n",
        "                    run_torch=False\n",
        "                 )\\\n",
        "                  .run_2_5(n_average=n_average,\n",
        "                            cluster_sizes=sizes,\n",
        "                            b = 5,\n",
        "                            w_averages=w_averages,\n",
        "                            att_averages=att_averages)\n",
        "with open('test_2_5.pickle', 'wb') as handle:\n",
        "    pickle.dump(stats, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "!cp \"/content/test_2_5.pickle\" \"/content/drive/MyDrive\""
      ],
      "metadata": {
        "id": "Zpr5g5JCzEkG"
      },
      "id": "Zpr5g5JCzEkG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_2_5=None\n",
        "with open(\"/content/drive/MyDrive/test_2_5.pickle\", 'rb') as handle:\n",
        "    test_2_5 = pickle.load(handle)\n",
        "test_2_5.keys()\n",
        "df = pd.DataFrame.from_dict(test_2_5)\n",
        "# labels = [ 'EM-GMM', 'SC', 'Algo1', 'attSBM','IR_sLS']\n",
        "# algos = [\"attributes\", \"graph\", \"ours\", \"attSBM\", \"IR_sLS\"]\n",
        "# saveFig = True\n",
        "# for varying in [\"graph\",\"attributes\"]:\n",
        "#   curves = []\n",
        "#   curves_std = []\n",
        "#   for algo in algos:\n",
        "#     curves.append(df.loc[(df['varying'] == varying) & (df['algorithm'] == algo)][\"ARI\"])\n",
        "#     curves_std.append(df.loc[(df['varying'] == varying) & (df['algorithm'] == algo)][\"ARI_std\"])\n",
        "#   if varying == 'graph':\n",
        "#     x = df.loc[(df['varying'] == \"graph\")][\"weights_avg\"].unique()\n",
        "#     fileName = 'N_' + str(n) + '_K_' + str(n_clusters) + '_att_' + str(2)  +  '_nAverage' + str(n_average) + '.jpeg'\n",
        "#     plotting( x, curves, labels, curves_std = curves_std, xticks = x, xlabel = 'weights_avg', saveFig = True, fileName = fileName )\n",
        "#     plt.close()\n",
        "#   elif varying == 'attributes':\n",
        "#     x = df.loc[(df['varying'] == \"attributes\")][\"attributes_avg\"].unique()\n",
        "#     fileName = 'N_' + str(n) + '_K_' + str(n_clusters) + '_w_' + str(2) + '_nAverage_' + str(n_average) + '.jpeg'\n",
        "#     plotting( x , curves, labels, curves_std = curves_std, xticks = x, xlabel = 'attributes_avg', saveFig = True, fileName = fileName )\n",
        "#     plt.close()"
      ],
      "metadata": {
        "id": "HROKJI17kQ-y"
      },
      "id": "HROKJI17kQ-y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Real Data"
      ],
      "metadata": {
        "id": "BCvSIxvhmD5j"
      },
      "id": "BCvSIxvhmD5j"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7942ed30",
      "metadata": {
        "id": "7942ed30"
      },
      "outputs": [],
      "source": [
        "attributes_distribution = \"bernoulli\"\n",
        "edge_distribution = \"bernoulli\"\n",
        "weight_distribution = \"gaussian\"\n",
        "benchmark = BregmanBenchmark(att_variance=1,\n",
        "                    attributes_distribution=attributes_distribution,\n",
        "                    weight_variance=1,\n",
        "                    weight_distribution=weight_distribution,\n",
        "                    edge_distribution=edge_distribution,\n",
        "                    run_torch=False,\n",
        "                    initializer = 'chernoff',\n",
        "                    hard_clustering=True)\n",
        "scores = benchmark.run_real_data(n_iters=1,n_runs=1)\n",
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('test_real_data.pickle', 'wb') as handle:\n",
        "    pickle.dump(scores, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "!cp \"/content/test_real_data.pickle\" \"/content/drive/MyDrive\""
      ],
      "metadata": {
        "id": "AnPjQFHPjp_t"
      },
      "id": "AnPjQFHPjp_t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores=None\n",
        "with open(\"/content/drive/MyDrive/test_real_data.pickle\", 'rb') as handle:\n",
        "    scores = pickle.load(handle)\n",
        "scores.keys()"
      ],
      "metadata": {
        "id": "YvBzPcj6B9eI"
      },
      "id": "YvBzPcj6B9eI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(scores)\n",
        "df_grouped = df.groupby(by=\"dataset\")\n",
        "for key, item in df_grouped:\n",
        "    print(df_grouped.get_group(key), \"\\n\\n\")"
      ],
      "metadata": {
        "id": "qEpRHoNLQeqd"
      },
      "id": "qEpRHoNLQeqd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "8HIAU4EvsC-0"
      },
      "id": "8HIAU4EvsC-0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Begin Plots"
      ],
      "metadata": {
        "id": "7rU3bGnAmO8n"
      },
      "id": "7rU3bGnAmO8n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f1ZvaasK7XH",
      "metadata": {
        "id": "8f1ZvaasK7XH"
      },
      "outputs": [],
      "source": [
        "from BregmanTests.utils import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3vN0pwvtM-Eo",
      "metadata": {
        "id": "3vN0pwvtM-Eo"
      },
      "outputs": [],
      "source": [
        "test_2_1=None\n",
        "with open(\"/content/drive/MyDrive/test_2_1.pickle\", 'rb') as handle:\n",
        "    test_2_1 = pickle.load(handle)\n",
        "test_2_1.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TrkQZoOAQae4",
      "metadata": {
        "id": "TrkQZoOAQae4"
      },
      "outputs": [],
      "source": [
        "scatter_(test_2_1,'a', 'r', 'ARI')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QY5bJiRenKe8",
      "metadata": {
        "id": "QY5bJiRenKe8"
      },
      "outputs": [],
      "source": [
        "scatter_with_colorbar(test_2_1,'a', 'r', 'ARI')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_2_4=None\n",
        "SIZE_TITLE = 24\n",
        "SIZE_LABELS = 24\n",
        "SIZE_TICKS = 18\n",
        "SIZE_LEGEND = 18\n",
        "with open(\"/content/drive/MyDrive/test_2_4.pickle\", 'rb') as handle:\n",
        "    test_2_4 = pickle.load(handle)\n",
        "fig = plt.figure(figsize=(5, 4))\n",
        "ax = fig.add_subplot(111)\n",
        "x,y,z = np.array(test_2_4[\"lambda_att\"]),np.array(test_2_4[\"lambda_w\"]),np.array(test_2_4[\"ARI\"])\n",
        "xlabel=\"attributes_avg\"\n",
        "ylabel=\"weights_avg\"\n",
        "C = ax.scatter(x=1/x,y=1/y,c=z,cmap=\"coolwarm\")\n",
        "plt.ylim(0.9,3.5)\n",
        "ticks = np.linspace(z.min(), z.max(), 5, endpoint=True)\n",
        "cb = fig.colorbar(C, ax=ax, fraction=0.02, pad=0.1, label='ARI',ticks=ticks)\n",
        "cb.set_label(label='ARI', size=SIZE_LEGEND)\n",
        "cb.ax.tick_params(labelsize=SIZE_TICKS)\n",
        "plt.xlabel( xlabel, fontsize = SIZE_LABELS )\n",
        "plt.ylabel( ylabel, fontsize = SIZE_LABELS )\n",
        "plt.xticks( fontsize = SIZE_TICKS )\n",
        "plt.yticks( fontsize = SIZE_TICKS )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wBuJ9YmNZqUu"
      },
      "id": "wBuJ9YmNZqUu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B8LRjwn2N3ja",
      "metadata": {
        "id": "B8LRjwn2N3ja"
      },
      "outputs": [],
      "source": [
        "x,y,z = test_2_1[\"a\"],test_2_1[\"r\"],test_2_1[\"ARI\"]\n",
        "vals_x = np.unique(x)\n",
        "vals_y = np.unique(y)\n",
        "\"\"\"\n",
        "len(X) == N is the number of columns in Z and len(Y) == M is the number of rows in Z.\n",
        "Z = M x N\n",
        "\"\"\"\n",
        "x = np.array(x).reshape(vals_x.shape[0],vals_y.shape[0])\n",
        "y = np.array(y).reshape(vals_x.shape[0],vals_y.shape[0])\n",
        "z = np.array(z).reshape(vals_x.shape[0],vals_y.shape[0]).T\n",
        "make_contour_plot(vals_x,vals_y,z,x_label=\"a\",y_label=\"r\",filename=\"contour_plot_2_1.jpeg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GzYD-jJYV6h4",
      "metadata": {
        "id": "GzYD-jJYV6h4"
      },
      "outputs": [],
      "source": [
        "test_2_2=None\n",
        "with open(\"/content/drive/MyDrive/test_2_2.pickle\", 'rb') as handle:\n",
        "    test_2_2 = pickle.load(handle)\n",
        "test_2_2.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OF2FxOgcV9Fp",
      "metadata": {
        "id": "OF2FxOgcV9Fp"
      },
      "outputs": [],
      "source": [
        "scatter_(test_2_2,'d', 'mu', 'ARI')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HcgfbcQMYA7-",
      "metadata": {
        "id": "HcgfbcQMYA7-"
      },
      "outputs": [],
      "source": [
        "x,y,z = test_2_2[\"d\"],test_2_2[\"mu\"],test_2_2[\"ARI\"]\n",
        "vals_x = np.unique(x)\n",
        "vals_y = np.unique(y)\n",
        "\"\"\"\n",
        "len(X) == N is the number of columns in Z and len(Y) == M is the number of rows in Z.\n",
        "Z = M x N\n",
        "\"\"\"\n",
        "x = np.array(x).reshape(vals_x.shape[0],vals_y.shape[0])\n",
        "y = np.array(y).reshape(vals_x.shape[0],vals_y.shape[0])\n",
        "# x,y = np.meshgrid(vals_x,vals_y)\n",
        "z = np.array(z).reshape(len(vals_x),len(vals_y)).T\n",
        "make_contour_plot(vals_x,vals_y,z,x_label=\"d\",y_label=\"mu\",filename=\"contour_plot_2_2.jpeg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tKwys6pKYU31",
      "metadata": {
        "id": "tKwys6pKYU31"
      },
      "outputs": [],
      "source": [
        "test_2_3=None\n",
        "with open(\"/content/drive/MyDrive/test_2_3.pickle\", 'rb') as handle:\n",
        "    test_2_3 = pickle.load(handle)\n",
        "test_2_3.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1Dk3He9t3kkn",
      "metadata": {
        "id": "1Dk3He9t3kkn"
      },
      "outputs": [],
      "source": [
        "x,y,z,data = test_2_3[\"d\"],test_2_3[\"lambda\"], test_2_3[\"a\"],test_2_3[\"ARI\"]\n",
        "vals_x = np.unique(x)\n",
        "vals_y = np.unique(y)\n",
        "vals_z = np.unique(z)\n",
        "\"\"\"\n",
        "len(X) == N is the number of columns in data,\n",
        "len(Y) == M is the number of rows in data.\n",
        "len(Z) == P is the depth of data\n",
        "DATA = M x N X P\n",
        "\"\"\"\n",
        "X = np.array(x).reshape(vals_x.shape[0],vals_y.shape[0],vals_z.shape[0])\n",
        "Y = np.array(y).reshape(vals_x.shape[0],vals_y.shape[0],vals_z.shape[0])\n",
        "Z = np.array(z).reshape(vals_x.shape[0],vals_y.shape[0],vals_z.shape[0])\n",
        "data = np.array(data).reshape(vals_x.shape[0],vals_y.shape[0],vals_z.shape[0])\n",
        "x_label=\"d\"\n",
        "y_label=\"lambda\"\n",
        "z_label = \"a\"\n",
        "\n",
        "kw = {\n",
        "        # 'vmin': data.min(),\n",
        "        # 'vmax': data.max()\n",
        "    }\n",
        "\n",
        "# Create a figure with 3D ax\n",
        "fig = plt.figure(figsize=(5, 4))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Set limits of the plot from coord limits\n",
        "xmin, xmax = X.min(), X.max()\n",
        "ymin, ymax = Y.min(), Y.max()\n",
        "zmin, zmax = Z.min(), Z.max()\n",
        "ax.set(xlim=[xmin, xmax], ylim=[ymin, ymax], zlim=[zmin, zmax])\n",
        "\n",
        "# Plot contour surfaces\n",
        "    ### This is the X x Y plane for z=zmax\n",
        "_ = ax.contourf(\n",
        "            X[:, :, -1], Y[:, :, -1], data[:, :, -1],\n",
        "            zdir='z', offset=zmax, **kw\n",
        "        )\n",
        "\n",
        "    ### This is the X x Y plane for z=zmin\n",
        "_ = ax.contourf(\n",
        "            X[:, :, 0], Y[:, :, 0], data[:, :, 0],\n",
        "            zdir='z', offset=zmin, **kw\n",
        "        )\n",
        "\n",
        "    ### This is the X x Z plane for y=ymax\n",
        "_ = ax.contourf(\n",
        "            X[-1, :, :], data[-1, :, :], Z[-1, :, :],\n",
        "            zdir='y', offset=ymax, **kw\n",
        "        )\n",
        "\n",
        "    ### This is the X x Z plane for y=ymin\n",
        "_ = ax.contourf(\n",
        "            X[0, :, :], data[0, :, :], Z[0, :, :],\n",
        "            zdir='y', offset=ymin, **kw\n",
        "        )\n",
        "\n",
        "    ### This is the Y x Z plane for x=xmax\n",
        "_ = ax.contourf(\n",
        "            data[:, -1, :], Y[:, -1, :], Z[:, -1, :],\n",
        "            zdir='x', offset=xmax, **kw\n",
        "        )\n",
        "\n",
        "    ### This is the Y x Z plane for x=xmin\n",
        "C = ax.contourf(\n",
        "            data[:, 0, :], Y[:, 0, :], Z[:, 0, :],\n",
        "            zdir='x', offset=xmin, **kw\n",
        "        )\n",
        "\n",
        "\n",
        "# Plot edges\n",
        "edges_kw = dict(color='0.4', linewidth=1,zorder=-1e3)\n",
        "ax.plot([xmax, xmax], [ymin, ymax], zmin, **edges_kw)\n",
        "ax.plot([xmin, xmax], [ymin, ymin], zmin, **edges_kw)\n",
        "ax.plot([xmin, xmax], [ymin, ymin], [zmin, zmax], **edges_kw)\n",
        "\n",
        "# Set labels and zticks\n",
        "ax.set(\n",
        "        xlabel=x_label,\n",
        "        ylabel=y_label,\n",
        "        zlabel=z_label\n",
        "    )\n",
        "\n",
        "# Set zoom and angle view\n",
        "ax.view_init(30, 45, 0)\n",
        "ax.set_box_aspect(None, zoom=0.9)\n",
        "\n",
        "# Colorbar\n",
        "fig.colorbar(C, ax=ax, fraction=0.02, pad=0.1, label='ARI')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "N2yOg0zK6osd",
      "metadata": {
        "id": "N2yOg0zK6osd"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(5, 4))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.set(\n",
        "        xlabel=x_label,\n",
        "        ylabel=y_label,\n",
        "        zlabel=z_label\n",
        "    )\n",
        "C = ax.scatter(xs=X,ys=Y,zs=Z,c=data)\n",
        "fig.colorbar(C, ax=ax, fraction=0.02, pad=0.2, label='ARI')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}