{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "jP3HrzLaFCl0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jP3HrzLaFCl0",
        "outputId": "5f9a828c-526d-48f5-92fd-ffba13c351b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "wqMKN-tSMM0L",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        },
        "id": "wqMKN-tSMM0L",
        "outputId": "38e98f05-0719-43a2-db6f-0b0af50b3a8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/FelipeSchreiber/BregmanClustering.git\n",
            "  Cloning https://github.com/FelipeSchreiber/BregmanClustering.git to /tmp/pip-req-build-s3s1zpb_\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/FelipeSchreiber/BregmanClustering.git /tmp/pip-req-build-s3s1zpb_\n",
            "  Resolved https://github.com/FelipeSchreiber/BregmanClustering.git to commit f763b97a57200d00f5445c0e51907de27e02de61\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: bregClust\n",
            "  Building wheel for bregClust (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bregClust: filename=bregClust-1.0-py3-none-any.whl size=34865 sha256=693356820d87fe47a63ed6f3483467bdecbefc5032a3396b12257b6d55b859ef\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vxrr63ze/wheels/3f/90/fb/833529540c1d5f19c385fde761cc07c664c4b9a5edf7c6735b\n",
            "Successfully built bregClust\n",
            "Installing collected packages: bregClust\n",
            "  Attempting uninstall: bregClust\n",
            "    Found existing installation: bregClust 1.0\n",
            "    Uninstalling bregClust-1.0:\n",
            "      Successfully uninstalled bregClust-1.0\n",
            "Successfully installed bregClust-1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "BregmanClustering",
                  "BregmanClusteringTorch",
                  "BregmanInitializer",
                  "BregmanTests"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.3.1)\n",
            "Requirement already satisfied: rpy2==3.5.1 in /usr/local/lib/python3.10/dist-packages (3.5.1)\n",
            "Requirement already satisfied: cffi>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from rpy2==3.5.1) (1.15.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from rpy2==3.5.1) (3.1.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from rpy2==3.5.1) (2022.7.1)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from rpy2==3.5.1) (4.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.27.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.10.0->rpy2==3.5.1) (2.21)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->rpy2==3.5.1) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
            "Requirement already satisfied: pytz-deprecation-shim in /usr/local/lib/python3.10/dist-packages (from tzlocal->rpy2==3.5.1) (0.1.0.post0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.10/dist-packages (from pytz-deprecation-shim->tzlocal->rpy2==3.5.1) (2023.3)\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall git+https://github.com/FelipeSchreiber/BregmanClustering.git --no-deps\n",
        "!pip install torch_geometric rpy2==3.5.1\n",
        "import os\n",
        "import pickle\n",
        "from sys import platform\n",
        "import BregmanTests\n",
        "os.chmod(BregmanTests.__path__[0]+\"/install_algos.sh\",777)\n",
        "if platform == \"win32\":\n",
        "    os.environ[\"R_HOME\"] = r\"C:\\\\Program Files\\R\\R-4.2.3\"\n",
        "else:\n",
        "    ### Uncomment line below if in Google Colab environment\n",
        "    print(os.path.isfile(BregmanTests.__path__[0]+\"/install_algos.sh\"))\n",
        "    ### Done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "4w2gsGfqMbhn",
      "metadata": {
        "id": "4w2gsGfqMbhn"
      },
      "outputs": [],
      "source": [
        "from BregmanTests.benchmark import *\n",
        "n_average = 20\n",
        "n = 600\n",
        "n_clusters = 2\n",
        "d = 1\n",
        "sizes = [ n // n_clusters ]*np.ones( n_clusters, dtype = int )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attributes_distribution = \"exponential\"\n",
        "edge_distribution = \"bernoulli\"\n",
        "weight_distribution = \"exponential\"\n",
        "att_averages = np.linspace(1,5,5)\n",
        "w_averages = np.array([1,3,6,9,12])\n",
        "stats = BregmanBenchmark(att_variance=n_average,\n",
        "                    attributes_distribution=attributes_distribution,\n",
        "                    weight_variance=1,\n",
        "                    weight_distribution=weight_distribution,\n",
        "                    edge_distribution=edge_distribution,\n",
        "                    run_torch=False\n",
        "                 )\\\n",
        "                  .run_2_5(n_average=n_average,\n",
        "                            cluster_sizes=sizes,\n",
        "                            b = 5,\n",
        "                            w_averages=w_averages,\n",
        "                            att_averages=att_averages)\n",
        "with open('test_2_5.pickle', 'wb') as handle:\n",
        "    pickle.dump(stats, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "!cp \"/content/test_2_5.pickle\" \"/content/drive/MyDrive\""
      ],
      "metadata": {
        "id": "Zpr5g5JCzEkG",
        "outputId": "95723778-4489-4847-9cee-88b4061f7072",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Zpr5g5JCzEkG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>>  graph\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 4/5 [45:18<11:27, 687.37s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_2_5=None\n",
        "with open(\"/content/drive/MyDrive/test_2_5.pickle\", 'rb') as handle:\n",
        "    test_2_5 = pickle.load(handle)\n",
        "test_2_5.keys()"
      ],
      "metadata": {
        "id": "HROKJI17kQ-y"
      },
      "id": "HROKJI17kQ-y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame.from_dict(test_2_5)"
      ],
      "metadata": {
        "id": "IwOmiZYfkXfh"
      },
      "id": "IwOmiZYfkXfh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attributes_distribution = \"exponential\"\n",
        "edge_distribution = \"bernoulli\"\n",
        "weight_distribution = \"exponential\"\n",
        "att_averages = np.linspace(1,5,10)\n",
        "w_averages = np.linspace(1,5,10)\n",
        "stats = BregmanBenchmark(att_variance=1,\n",
        "                    attributes_distribution=attributes_distribution,\n",
        "                    weight_variance=1,\n",
        "                    weight_distribution=weight_distribution,\n",
        "                    edge_distribution=edge_distribution,\n",
        "                    run_torch=False\n",
        "                 )\\\n",
        "                  .run_2_4(n_average=10,\n",
        "                            cluster_sizes=sizes,\n",
        "                            b = 5,\n",
        "                            w_averages=w_averages,\n",
        "                            att_averages=att_averages)\n",
        "with open('test_2_4.pickle', 'wb') as handle:\n",
        "    pickle.dump(stats, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "!cp \"/content/test_2_4.pickle\" \"/content/drive/MyDrive\""
      ],
      "metadata": {
        "id": "isj4xK4sGdg9",
        "outputId": "26ecb724-8e23-4b48-94ad-ecaab843926f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        }
      },
      "id": "isj4xK4sGdg9",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2it [06:13, 186.63s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-342bf11d9d77>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0matt_averages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mw_averages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m stats = BregmanBenchmark(att_variance=1,\n\u001b[0m\u001b[1;32m      7\u001b[0m                     \u001b[0mattributes_distribution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattributes_distribution\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mweight_variance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/BregmanTests/benchmark.py\u001b[0m in \u001b[0;36mrun_2_4\u001b[0;34m(self, n_average, cluster_sizes, w_averages, att_averages, b, dense, binary, n_iters)\u001b[0m\n\u001b[1;32m    589\u001b[0m                     \u001b[0mz_pred_both\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgraph_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m                     \u001b[0mz_pred_both\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m                 \u001b[0maris_both\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0madjusted_rand_score\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mz_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_pred_both\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m                 \u001b[0maris_both_mean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0maris_both\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/BregmanClustering/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, A, X, Y, Z_init)\u001b[0m\n\u001b[1;32m    825\u001b[0m         \u001b[0miteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mconvergence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m             \u001b[0mnew_memberships\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massignments\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribute_means\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputeAttributeMeans\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_memberships\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/BregmanClustering/models.py\u001b[0m in \u001b[0;36massignments\u001b[0;34m(self, A, X, Y)\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribute_means\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribute_divergence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m             \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingleNodeAssignment\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfromVectorToMembershipMatrice\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_clusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_clusters\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/BregmanClustering/models.py\u001b[0m in \u001b[0;36msingleNodeAssignment\u001b[0;34m(self, A, X, H, node)\u001b[0m\n\u001b[1;32m    929\u001b[0m             \"\"\"\n\u001b[1;32m    930\u001b[0m             \u001b[0matt_div\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             \u001b[0mgraph_div\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_divergence\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m             edge_div = np.sum( paired_distances(X[node,self.edge_index[1][node_indices],:],\\\n\u001b[1;32m    933\u001b[0m                                                  \u001b[0mE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv_indices_out\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/BregmanClustering/divergences.py\u001b[0m in \u001b[0;36mlogistic_loss\u001b[0;34m(X, M)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#Bernoulli | Logistic loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mlogistic_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mM\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m#total = np.log(1 + np.exp(- (2*X - 1) * ( np.log(M/(1-M)) ) )) as stated in the paper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7942ed30",
      "metadata": {
        "id": "7942ed30"
      },
      "outputs": [],
      "source": [
        "# attributes_distribution = \"bernoulli\"\n",
        "# edge_distribution = \"bernoulli\"\n",
        "# weight_distribution = \"gaussian\"\n",
        "# scores = BregmanBenchmark(att_variance=1,\n",
        "#                     attributes_distribution=attributes_distribution,\n",
        "#                     weight_variance=1,\n",
        "#                     weight_distribution=weight_distribution,\n",
        "#                     edge_distribution=edge_distribution,\n",
        "#                     run_torch=False)\\\n",
        "#                   .run_real_data()\n",
        "# scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UJ_dbuJWeAn8",
      "metadata": {
        "id": "UJ_dbuJWeAn8"
      },
      "outputs": [],
      "source": [
        "# attributes_distribution = \"gaussian\"\n",
        "# edge_distribution = \"bernoulli\"\n",
        "# weight_distribution = \"exponential\"\n",
        "# BregmanBenchmark(att_variance=1,\n",
        "#                     attributes_distribution=attributes_distribution,\n",
        "#                     weight_variance=1,\n",
        "#                     weight_distribution=weight_distribution,\n",
        "#                     edge_distribution=edge_distribution,\n",
        "#                     run_torch=False)\\\n",
        "#                  .run_test(n_average=n_average,cluster_sizes=sizes,\\\n",
        "#                  b=5,\\\n",
        "#                  a_range=[ 5,7,9,11,13,15 ],\\\n",
        "#                  r_range = [ 0,1,2,3,4,5 ],\\\n",
        "#                  dense=False,\\\n",
        "#                  binary=True,\\\n",
        "#                  file_endings=\".jpeg\",\\\n",
        "#                  n_iters=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1QGRHlHVMvL4",
      "metadata": {
        "id": "1QGRHlHVMvL4"
      },
      "outputs": [],
      "source": [
        "attributes_distribution = \"gaussian\"\n",
        "edge_distribution = \"bernoulli\"\n",
        "weight_distribution = \"exponential\"\n",
        "a_range = np.linspace(5,14,1)\n",
        "r_range = np.linspace(0,0.7,1)*np.log(n)\n",
        "stats = BregmanBenchmark(att_variance=1,\n",
        "                    attributes_distribution=attributes_distribution,\n",
        "                    weight_variance=1,\n",
        "                    weight_distribution=weight_distribution,\n",
        "                    edge_distribution=edge_distribution,\n",
        "                    run_torch=False)\\\n",
        "                  .run_2_1(n_average=1,\n",
        "                            cluster_sizes=sizes,\n",
        "                            b=5,\n",
        "                            a_range= a_range,\n",
        "                            r_range = r_range,\n",
        "                            dense=False,\n",
        "                            binary=True)\n",
        "with open('test_2_1.pickle', 'wb') as handle:\n",
        "    pickle.dump(stats, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "!cp \"/content/test_2_1.pickle\" \"/content/drive/MyDrive\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XYNgyTRXEhrK",
      "metadata": {
        "id": "XYNgyTRXEhrK"
      },
      "outputs": [],
      "source": [
        "# attributes_distribution = \"poisson\"\n",
        "# edge_distribution = \"bernoulli\"\n",
        "# weight_distribution = \"gaussian\"\n",
        "# d_range = np.arange(1,6)\n",
        "# mu_range = np.linspace(0,6,20)\n",
        "# att_centers = np.arange(1,4).reshape(-1,1)\n",
        "# stats = BregmanBenchmark(att_variance=1,\n",
        "#                     attributes_distribution=attributes_distribution,\n",
        "#                     weight_variance=1,\n",
        "#                     weight_distribution=weight_distribution,\n",
        "#                     edge_distribution=edge_distribution,\n",
        "#                     att_centers=att_centers,\n",
        "#                     run_torch=False\n",
        "#                   )\\\n",
        "#                   .run_2_2(n_average=10,\n",
        "#                             cluster_sizes=sizes,\n",
        "#                              d_range = d_range,\n",
        "#                              mu_range = mu_range,\n",
        "#                              dense=True,\n",
        "#                              binary=False)\n",
        "# with open('test_2_2.pickle', 'wb') as handle:\n",
        "#     pickle.dump(stats, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "# !cp \"/content/test_2_2.pickle\" \"/content/drive/MyDrive\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GdUwRBlstRH-",
      "metadata": {
        "id": "GdUwRBlstRH-"
      },
      "outputs": [],
      "source": [
        "attributes_distribution = \"poisson\"\n",
        "edge_distribution = \"bernoulli\"\n",
        "weight_distribution = \"exponential\"\n",
        "d_range = np.arange(1,5)\n",
        "a_range = np.linspace(5,14,10)\n",
        "lambda_range = np.arange(1,6)\n",
        "att_centers = np.arange(1,4).reshape(-1,1)\n",
        "stats = BregmanBenchmark(att_variance=1,\n",
        "                    attributes_distribution=attributes_distribution,\n",
        "                    weight_variance=1,\n",
        "                    weight_distribution=weight_distribution,\n",
        "                    edge_distribution=edge_distribution,\n",
        "                    att_centers=att_centers,\n",
        "                    run_torch=False\n",
        "                 )\\\n",
        "                  .run_2_3(n_average=10,\n",
        "                            cluster_sizes=sizes,\n",
        "                            d_range= d_range,\n",
        "                            lambda_range = lambda_range,\n",
        "                            a_range = a_range,\n",
        "                            b = 5,\n",
        "                            dense=False,\n",
        "                            binary=False)\n",
        "with open('test_2_3.pickle', 'wb') as handle:\n",
        "    pickle.dump(stats, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "!cp \"/content/test_2_3.pickle\" \"/content/drive/MyDrive\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f1ZvaasK7XH",
      "metadata": {
        "id": "8f1ZvaasK7XH"
      },
      "outputs": [],
      "source": [
        "from BregmanTests.utils import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3vN0pwvtM-Eo",
      "metadata": {
        "id": "3vN0pwvtM-Eo"
      },
      "outputs": [],
      "source": [
        "test_2_1=None\n",
        "with open(\"/content/drive/MyDrive/test_2_1.pickle\", 'rb') as handle:\n",
        "    test_2_1 = pickle.load(handle)\n",
        "test_2_1.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TrkQZoOAQae4",
      "metadata": {
        "id": "TrkQZoOAQae4"
      },
      "outputs": [],
      "source": [
        "def scatter_(dict_,x_name,y_name,z_name):\n",
        "  fig, ax = plt.subplots()\n",
        "  x,y = dict_[x_name],dict_[y_name]\n",
        "  ax.scatter(x,y)\n",
        "  for i, txt in enumerate(dict_[z_name]):\n",
        "      ax.annotate(\"{:.2f}\".format(txt), (x[i], y[i]))\n",
        "  ax.set_xlabel(x_name)\n",
        "  ax.set_ylabel(y_name)\n",
        "scatter_(test_2_1,'a', 'r', 'ARI')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QY5bJiRenKe8",
      "metadata": {
        "id": "QY5bJiRenKe8"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(5, 4))\n",
        "ax = fig.add_subplot(111)\n",
        "x,y,z = test_2_1[\"a\"],test_2_1[\"r\"],test_2_1[\"ARI\"]\n",
        "ax.set(\n",
        "        xlabel=\"a\",\n",
        "        ylabel=\"r\"\n",
        "    )\n",
        "C = ax.scatter(x=x,y=y,c=z)\n",
        "fig.colorbar(C, ax=ax, fraction=0.02, pad=0.2, label='ARI')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_2_4=None\n",
        "SIZE_TITLE = 24\n",
        "SIZE_LABELS = 24\n",
        "SIZE_TICKS = 18\n",
        "SIZE_LEGEND = 18\n",
        "with open(\"/content/drive/MyDrive/test_2_4.pickle\", 'rb') as handle:\n",
        "    test_2_4 = pickle.load(handle)\n",
        "fig = plt.figure(figsize=(5, 4))\n",
        "ax = fig.add_subplot(111)\n",
        "x,y,z = np.array(test_2_4[\"lambda_att\"]),np.array(test_2_4[\"lambda_w\"]),np.array(test_2_4[\"ARI\"])\n",
        "xlabel=\"attributes_avg\"\n",
        "ylabel=\"weights_avg\"\n",
        "C = ax.scatter(x=1/x,y=1/y,c=z,cmap=\"coolwarm\")\n",
        "plt.ylim(0.9,3.5)\n",
        "ticks = np.linspace(z.min(), z.max(), 5, endpoint=True)\n",
        "cb = fig.colorbar(C, ax=ax, fraction=0.02, pad=0.1, label='ARI',ticks=ticks)\n",
        "cb.set_label(label='ARI', size=SIZE_LEGEND)\n",
        "cb.ax.tick_params(labelsize=SIZE_TICKS)\n",
        "plt.xlabel( xlabel, fontsize = SIZE_LABELS )\n",
        "plt.ylabel( ylabel, fontsize = SIZE_LABELS )\n",
        "plt.xticks( fontsize = SIZE_TICKS )\n",
        "plt.yticks( fontsize = SIZE_TICKS )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wBuJ9YmNZqUu"
      },
      "id": "wBuJ9YmNZqUu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B8LRjwn2N3ja",
      "metadata": {
        "id": "B8LRjwn2N3ja"
      },
      "outputs": [],
      "source": [
        "x,y,z = test_2_1[\"a\"],test_2_1[\"r\"],test_2_1[\"ARI\"]\n",
        "vals_x = np.unique(x)\n",
        "vals_y = np.unique(y)\n",
        "\"\"\"\n",
        "len(X) == N is the number of columns in Z and len(Y) == M is the number of rows in Z.\n",
        "Z = M x N\n",
        "\"\"\"\n",
        "x = np.array(x).reshape(vals_x.shape[0],vals_y.shape[0])\n",
        "y = np.array(y).reshape(vals_x.shape[0],vals_y.shape[0])\n",
        "z = np.array(z).reshape(vals_x.shape[0],vals_y.shape[0]).T\n",
        "make_contour_plot(vals_x,vals_y,z,x_label=\"a\",y_label=\"r\",filename=\"contour_plot_2_1.jpeg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GzYD-jJYV6h4",
      "metadata": {
        "id": "GzYD-jJYV6h4"
      },
      "outputs": [],
      "source": [
        "test_2_2=None\n",
        "with open(\"/content/drive/MyDrive/test_2_2.pickle\", 'rb') as handle:\n",
        "    test_2_2 = pickle.load(handle)\n",
        "test_2_2.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OF2FxOgcV9Fp",
      "metadata": {
        "id": "OF2FxOgcV9Fp"
      },
      "outputs": [],
      "source": [
        "scatter_(test_2_2,'d', 'mu', 'ARI')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HcgfbcQMYA7-",
      "metadata": {
        "id": "HcgfbcQMYA7-"
      },
      "outputs": [],
      "source": [
        "x,y,z = test_2_2[\"d\"],test_2_2[\"mu\"],test_2_2[\"ARI\"]\n",
        "vals_x = np.unique(x)\n",
        "vals_y = np.unique(y)\n",
        "\"\"\"\n",
        "len(X) == N is the number of columns in Z and len(Y) == M is the number of rows in Z.\n",
        "Z = M x N\n",
        "\"\"\"\n",
        "x = np.array(x).reshape(vals_x.shape[0],vals_y.shape[0])\n",
        "y = np.array(y).reshape(vals_x.shape[0],vals_y.shape[0])\n",
        "# x,y = np.meshgrid(vals_x,vals_y)\n",
        "z = np.array(z).reshape(len(vals_x),len(vals_y)).T\n",
        "make_contour_plot(vals_x,vals_y,z,x_label=\"d\",y_label=\"mu\",filename=\"contour_plot_2_2.jpeg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tKwys6pKYU31",
      "metadata": {
        "id": "tKwys6pKYU31"
      },
      "outputs": [],
      "source": [
        "test_2_3=None\n",
        "with open(\"/content/drive/MyDrive/test_2_3.pickle\", 'rb') as handle:\n",
        "    test_2_3 = pickle.load(handle)\n",
        "test_2_3.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1Dk3He9t3kkn",
      "metadata": {
        "id": "1Dk3He9t3kkn"
      },
      "outputs": [],
      "source": [
        "x,y,z,data = test_2_3[\"d\"],test_2_3[\"lambda\"], test_2_3[\"a\"],test_2_3[\"ARI\"]\n",
        "vals_x = np.unique(x)\n",
        "vals_y = np.unique(y)\n",
        "vals_z = np.unique(z)\n",
        "\"\"\"\n",
        "len(X) == N is the number of columns in data,\n",
        "len(Y) == M is the number of rows in data.\n",
        "len(Z) == P is the depth of data\n",
        "DATA = M x N X P\n",
        "\"\"\"\n",
        "X = np.array(x).reshape(vals_x.shape[0],vals_y.shape[0],vals_z.shape[0])\n",
        "Y = np.array(y).reshape(vals_x.shape[0],vals_y.shape[0],vals_z.shape[0])\n",
        "Z = np.array(z).reshape(vals_x.shape[0],vals_y.shape[0],vals_z.shape[0])\n",
        "data = np.array(data).reshape(vals_x.shape[0],vals_y.shape[0],vals_z.shape[0])\n",
        "x_label=\"d\"\n",
        "y_label=\"lambda\"\n",
        "z_label = \"a\"\n",
        "\n",
        "kw = {\n",
        "        # 'vmin': data.min(),\n",
        "        # 'vmax': data.max()\n",
        "    }\n",
        "\n",
        "# Create a figure with 3D ax\n",
        "fig = plt.figure(figsize=(5, 4))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Set limits of the plot from coord limits\n",
        "xmin, xmax = X.min(), X.max()\n",
        "ymin, ymax = Y.min(), Y.max()\n",
        "zmin, zmax = Z.min(), Z.max()\n",
        "ax.set(xlim=[xmin, xmax], ylim=[ymin, ymax], zlim=[zmin, zmax])\n",
        "\n",
        "# Plot contour surfaces\n",
        "    ### This is the X x Y plane for z=zmax \n",
        "_ = ax.contourf(\n",
        "            X[:, :, -1], Y[:, :, -1], data[:, :, -1],\n",
        "            zdir='z', offset=zmax, **kw\n",
        "        )\n",
        "    \n",
        "    ### This is the X x Y plane for z=zmin \n",
        "_ = ax.contourf(\n",
        "            X[:, :, 0], Y[:, :, 0], data[:, :, 0],\n",
        "            zdir='z', offset=zmin, **kw\n",
        "        )\n",
        "\n",
        "    ### This is the X x Z plane for y=ymax \n",
        "_ = ax.contourf(\n",
        "            X[-1, :, :], data[-1, :, :], Z[-1, :, :],\n",
        "            zdir='y', offset=ymax, **kw\n",
        "        )\n",
        "\n",
        "    ### This is the X x Z plane for y=ymin \n",
        "_ = ax.contourf(\n",
        "            X[0, :, :], data[0, :, :], Z[0, :, :],\n",
        "            zdir='y', offset=ymin, **kw\n",
        "        )\n",
        "\n",
        "    ### This is the Y x Z plane for x=xmax \n",
        "_ = ax.contourf(\n",
        "            data[:, -1, :], Y[:, -1, :], Z[:, -1, :],\n",
        "            zdir='x', offset=xmax, **kw\n",
        "        )\n",
        "\n",
        "    ### This is the Y x Z plane for x=xmin\n",
        "C = ax.contourf(\n",
        "            data[:, 0, :], Y[:, 0, :], Z[:, 0, :],\n",
        "            zdir='x', offset=xmin, **kw\n",
        "        )\n",
        "\n",
        "\n",
        "# Plot edges\n",
        "edges_kw = dict(color='0.4', linewidth=1,zorder=-1e3)\n",
        "ax.plot([xmax, xmax], [ymin, ymax], zmin, **edges_kw)\n",
        "ax.plot([xmin, xmax], [ymin, ymin], zmin, **edges_kw)\n",
        "ax.plot([xmin, xmax], [ymin, ymin], [zmin, zmax], **edges_kw)\n",
        "\n",
        "# Set labels and zticks\n",
        "ax.set(\n",
        "        xlabel=x_label,\n",
        "        ylabel=y_label,\n",
        "        zlabel=z_label\n",
        "    )\n",
        "\n",
        "# Set zoom and angle view\n",
        "ax.view_init(30, 45, 0)\n",
        "ax.set_box_aspect(None, zoom=0.9)\n",
        "\n",
        "# Colorbar\n",
        "fig.colorbar(C, ax=ax, fraction=0.02, pad=0.1, label='ARI')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "N2yOg0zK6osd",
      "metadata": {
        "id": "N2yOg0zK6osd"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(5, 4))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.set(\n",
        "        xlabel=x_label,\n",
        "        ylabel=y_label,\n",
        "        zlabel=z_label\n",
        "    )\n",
        "C = ax.scatter(xs=X,ys=Y,zs=Z,c=data)\n",
        "fig.colorbar(C, ax=ax, fraction=0.02, pad=0.2, label='ARI')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}