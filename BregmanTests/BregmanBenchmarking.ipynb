{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "jP3HrzLaFCl0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jP3HrzLaFCl0",
        "outputId": "4d85bf24-551d-4dc5-e982-71caa99014a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "wqMKN-tSMM0L",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqMKN-tSMM0L",
        "outputId": "c9a26a34-1f6c-4053-dc6b-654802c4266d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/FelipeSchreiber/BregmanClustering.git\n",
            "  Cloning https://github.com/FelipeSchreiber/BregmanClustering.git to /tmp/pip-req-build-rnlhoyc3\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/FelipeSchreiber/BregmanClustering.git /tmp/pip-req-build-rnlhoyc3\n",
            "  Resolved https://github.com/FelipeSchreiber/BregmanClustering.git to commit 1b31a140daae269c196c075f82100695ad2b90e7\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: bregClust\n",
            "  Building wheel for bregClust (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bregClust: filename=bregClust-1.0-py3-none-any.whl size=42104 sha256=96e00baabf458d02dba4668a70fbc0c9acb77994dc382ce78c29bb473687fc72\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zzdcpoz2/wheels/3f/90/fb/833529540c1d5f19c385fde761cc07c664c4b9a5edf7c6735b\n",
            "Successfully built bregClust\n",
            "Installing collected packages: bregClust\n",
            "  Attempting uninstall: bregClust\n",
            "    Found existing installation: bregClust 1.0\n",
            "    Uninstalling bregClust-1.0:\n",
            "      Successfully uninstalled bregClust-1.0\n",
            "Successfully installed bregClust-1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.3.1)\n",
            "Requirement already satisfied: rpy2==3.5.1 in /usr/local/lib/python3.10/dist-packages (3.5.1)\n",
            "Requirement already satisfied: cffi>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from rpy2==3.5.1) (1.15.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from rpy2==3.5.1) (3.1.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from rpy2==3.5.1) (2022.7.1)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from rpy2==3.5.1) (4.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.27.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.10.0->rpy2==3.5.1) (2.21)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->rpy2==3.5.1) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
            "Requirement already satisfied: pytz-deprecation-shim in /usr/local/lib/python3.10/dist-packages (from tzlocal->rpy2==3.5.1) (0.1.0.post0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.10/dist-packages (from pytz-deprecation-shim->tzlocal->rpy2==3.5.1) (2023.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.10/dist-packages (0.5.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.10.1)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.56.4)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.5.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from umap-learn) (4.65.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.49->umap-learn) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.49->umap-learn) (67.7.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pynndescent>=0.5->umap-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->umap-learn) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: igraph in /usr/local/lib/python3.10/dist-packages (0.10.4)\n",
            "Requirement already satisfied: leidenalg in /usr/local/lib/python3.10/dist-packages (0.9.1)\n",
            "Requirement already satisfied: texttable>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from igraph) (1.6.7)\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall git+https://github.com/FelipeSchreiber/BregmanClustering.git --no-deps\n",
        "!pip install torch_geometric rpy2==3.5.1\n",
        "!pip install umap-learn\n",
        "!pip install igraph leidenalg\n",
        "import os\n",
        "import pickle\n",
        "from sys import platform\n",
        "import BregmanTests\n",
        "os.chmod(BregmanTests.__path__[0]+\"/install_algos.sh\",777)\n",
        "if platform == \"win32\":\n",
        "    os.environ[\"R_HOME\"] = r\"C:\\\\Program Files\\R\\R-4.2.3\"\n",
        "else:\n",
        "    ### Uncomment line below if in Google Colab environment\n",
        "    print(os.path.isfile(BregmanTests.__path__[0]+\"/install_algos.sh\"))\n",
        "    ### Done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4w2gsGfqMbhn",
      "metadata": {
        "id": "4w2gsGfqMbhn"
      },
      "outputs": [],
      "source": [
        "from BregmanTests.benchmark import *\n",
        "n_average = 20\n",
        "n = 600\n",
        "n_clusters = 2\n",
        "d = 1\n",
        "sizes = [ n // n_clusters ]*np.ones( n_clusters, dtype = int )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attributes_distribution = \"gaussian\"\n",
        "edge_distribution = \"bernoulli\"\n",
        "weight_distribution = \"exponential\"\n",
        "a_range = np.linspace(5,14,3)\n",
        "r_range = np.linspace(0,0.7,3)*np.log(n)\n",
        "benchmark = BregmanBenchmark(att_variance=1,\n",
        "                    attributes_distribution=attributes_distribution,\n",
        "                    weight_variance=1,\n",
        "                    weight_distribution=weight_distribution,\n",
        "                    edge_distribution=edge_distribution,\n",
        "                    run_torch=True,\n",
        "                    initializer = 'AIC',\n",
        "                    hard_clustering=True)\n",
        "benchmark.run_test(n_average=1,cluster_sizes=sizes,\\\n",
        "                 b=5,\\\n",
        "                 a_range=[ 5,7,9,11,13,15 ],\\\n",
        "                 r_range = [ 0,1,2,3,4,5 ],\\\n",
        "                 dense=False,\\\n",
        "                 binary=True,\\\n",
        "                 file_endings=\".jpeg\",\\\n",
        "                 n_iters=25)"
      ],
      "metadata": {
        "id": "BRK9Lc7TXYNe",
        "outputId": "50cc4f0a-ce79-463a-8d4b-a36ca2aafb9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        }
      },
      "id": "BRK9Lc7TXYNe",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/6 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SBM:  [[0.0852924  0.05330775]\n",
            " [0.05330775 0.0852924 ]]\n",
            "\n",
            "Distribution Centers:  [[0.0, 0.0], [-0.0, 0.0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-24e5b42e4e4a>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'AIC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                     hard_clustering=True)\n\u001b[0;32m---> 14\u001b[0;31m benchmark.run_test(n_average=1,cluster_sizes=sizes,\\\n\u001b[0m\u001b[1;32m     15\u001b[0m                  \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                  \u001b[0ma_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/BregmanTests/benchmark.py\u001b[0m in \u001b[0;36mrun_test\u001b[0;34m(self, n_average, cluster_sizes, b, a_range, r_range, dense, binary, file_endings, n_iters)\u001b[0m\n\u001b[1;32m    251\u001b[0m                         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                     \u001b[0;31m## For comparison purposes, the initialization is the same for IR-sLS, IR-LS and ours\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massignInitialLabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                     \u001b[0mz_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicted_memberships\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/BregmanClusteringTorch/torch_models.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self, X, Y, edge_index)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_random_init\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mZ_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mZ_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicted_memberships\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicted_memberships\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemberships_from_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemberships_from_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/BregmanInitializer/init_cluster.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self, X, Y, edge_index, Z_init)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;31m## CASE X is N x N x 1: pass to |E| x 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m             \u001b[0msim_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "break"
      ],
      "metadata": {
        "id": "P7eaRWHE-d8H"
      },
      "id": "P7eaRWHE-d8H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test 2_1"
      ],
      "metadata": {
        "id": "4oK8WTsVlLci"
      },
      "id": "4oK8WTsVlLci"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run numpy model"
      ],
      "metadata": {
        "id": "bSqHh5mkgtYf"
      },
      "id": "bSqHh5mkgtYf"
    },
    {
      "cell_type": "code",
      "source": [
        "attributes_distribution = \"gaussian\"\n",
        "edge_distribution = \"bernoulli\"\n",
        "weight_distribution = \"exponential\"\n",
        "a_range = np.linspace(5,14,3)\n",
        "r_range = np.linspace(0,0.7,3)*np.log(n)\n",
        "benchmark = BregmanBenchmark(att_variance=1,\n",
        "                    attributes_distribution=attributes_distribution,\n",
        "                    weight_variance=1,\n",
        "                    weight_distribution=weight_distribution,\n",
        "                    edge_distribution=edge_distribution,\n",
        "                    run_torch=False,\n",
        "                    initializer = 'AIC',\n",
        "                    hard_clustering=True)\n",
        "stats = benchmark.run_2_1(n_average=1,\n",
        "                            cluster_sizes=sizes,\n",
        "                            b=5,\n",
        "                            a_range= a_range,\n",
        "                            r_range = r_range,\n",
        "                            dense=False,\n",
        "                            binary=True,\n",
        "                            strategy = 3,\n",
        "                            n_iters=25)\n",
        "with open('test_2_1.pickle', 'wb') as handle:\n",
        "    pickle.dump(stats, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "!cp \"/content/test_2_1.pickle\" \"/content/drive/MyDrive\""
      ],
      "metadata": {
        "id": "v4iSOddDO2qs"
      },
      "id": "v4iSOddDO2qs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run torch model"
      ],
      "metadata": {
        "id": "w_rMJxzygfZl"
      },
      "id": "w_rMJxzygfZl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1QGRHlHVMvL4",
      "metadata": {
        "id": "1QGRHlHVMvL4"
      },
      "outputs": [],
      "source": [
        "attributes_distribution = \"gaussian\"\n",
        "edge_distribution = \"bernoulli\"\n",
        "weight_distribution = \"exponential\"\n",
        "a_range = np.linspace(5,14,3)\n",
        "r_range = np.linspace(0,0.7,3)*np.log(n)\n",
        "stats = BregmanBenchmark(att_variance=1,\n",
        "                    attributes_distribution=attributes_distribution,\n",
        "                    weight_variance=1,\n",
        "                    weight_distribution=weight_distribution,\n",
        "                    edge_distribution=edge_distribution,\n",
        "                    run_torch=True,\n",
        "                    initializer = 'chernoff')\\\n",
        "                  .run_2_1(n_average=1,\n",
        "                            cluster_sizes=sizes,\n",
        "                            b=5,\n",
        "                            a_range= a_range,\n",
        "                            r_range = r_range,\n",
        "                            dense=False,\n",
        "                            binary=True)\n",
        "with open('test_2_1.pickle', 'wb') as handle:\n",
        "    pickle.dump(stats, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "!cp \"/content/test_2_1.pickle\" \"/content/drive/MyDrive\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test 2_2"
      ],
      "metadata": {
        "id": "VVVPpsn8l01D"
      },
      "id": "VVVPpsn8l01D"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XYNgyTRXEhrK",
      "metadata": {
        "id": "XYNgyTRXEhrK"
      },
      "outputs": [],
      "source": [
        "attributes_distribution = \"poisson\"\n",
        "edge_distribution = \"bernoulli\"\n",
        "weight_distribution = \"gaussian\"\n",
        "d_range = np.arange(1,6)\n",
        "mu_range = np.linspace(0,6,20)\n",
        "att_centers = np.arange(1,4).reshape(-1,1)\n",
        "stats = BregmanBenchmark(att_variance=1,\n",
        "                    attributes_distribution=attributes_distribution,\n",
        "                    weight_variance=1,\n",
        "                    weight_distribution=weight_distribution,\n",
        "                    edge_distribution=edge_distribution,\n",
        "                    att_centers=att_centers,\n",
        "                    run_torch=False\n",
        "                  )\\\n",
        "                  .run_2_2(n_average=10,\n",
        "                            cluster_sizes=sizes,\n",
        "                             d_range = d_range,\n",
        "                             mu_range = mu_range,\n",
        "                             dense=True,\n",
        "                             binary=False)\n",
        "with open('test_2_2.pickle', 'wb') as handle:\n",
        "    pickle.dump(stats, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "!cp \"/content/test_2_2.pickle\" \"/content/drive/MyDrive\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test 2_3"
      ],
      "metadata": {
        "id": "XlpxvjqBlt3q"
      },
      "id": "XlpxvjqBlt3q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GdUwRBlstRH-",
      "metadata": {
        "id": "GdUwRBlstRH-"
      },
      "outputs": [],
      "source": [
        "attributes_distribution = \"poisson\"\n",
        "edge_distribution = \"bernoulli\"\n",
        "weight_distribution = \"exponential\"\n",
        "d_range = np.arange(1,5)\n",
        "a_range = np.linspace(5,14,10)\n",
        "lambda_range = np.arange(1,6)\n",
        "att_centers = np.arange(1,4).reshape(-1,1)\n",
        "stats = BregmanBenchmark(att_variance=1,\n",
        "                    attributes_distribution=attributes_distribution,\n",
        "                    weight_variance=1,\n",
        "                    weight_distribution=weight_distribution,\n",
        "                    edge_distribution=edge_distribution,\n",
        "                    att_centers=att_centers,\n",
        "                    run_torch=False\n",
        "                 )\\\n",
        "                  .run_2_3(n_average=10,\n",
        "                            cluster_sizes=sizes,\n",
        "                            d_range= d_range,\n",
        "                            lambda_range = lambda_range,\n",
        "                            a_range = a_range,\n",
        "                            b = 5,\n",
        "                            dense=False,\n",
        "                            binary=False)\n",
        "with open('test_2_3.pickle', 'wb') as handle:\n",
        "    pickle.dump(stats, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "!cp \"/content/test_2_3.pickle\" \"/content/drive/MyDrive\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test 2_4"
      ],
      "metadata": {
        "id": "HcYf4xKeleyK"
      },
      "id": "HcYf4xKeleyK"
    },
    {
      "cell_type": "code",
      "source": [
        "attributes_distribution = \"exponential\"\n",
        "edge_distribution = \"bernoulli\"\n",
        "weight_distribution = \"exponential\"\n",
        "att_averages = np.linspace(1,5,10)\n",
        "w_averages = np.linspace(1,5,10)\n",
        "stats = BregmanBenchmark(att_variance=1,\n",
        "                    attributes_distribution=attributes_distribution,\n",
        "                    weight_variance=1,\n",
        "                    weight_distribution=weight_distribution,\n",
        "                    edge_distribution=edge_distribution,\n",
        "                    run_torch=False\n",
        "                 )\\\n",
        "                  .run_2_4(n_average=10,\n",
        "                            cluster_sizes=sizes,\n",
        "                            b = 5,\n",
        "                            w_averages=w_averages,\n",
        "                            att_averages=att_averages)\n",
        "with open('test_2_4.pickle', 'wb') as handle:\n",
        "    pickle.dump(stats, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "!cp \"/content/test_2_4.pickle\" \"/content/drive/MyDrive\""
      ],
      "metadata": {
        "id": "isj4xK4sGdg9"
      },
      "id": "isj4xK4sGdg9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test 2_5"
      ],
      "metadata": {
        "id": "JWvoW4tklTOT"
      },
      "id": "JWvoW4tklTOT"
    },
    {
      "cell_type": "code",
      "source": [
        "attributes_distribution = \"exponential\"\n",
        "edge_distribution = \"bernoulli\"\n",
        "weight_distribution = \"exponential\"\n",
        "att_averages = np.linspace(1,5,5)\n",
        "w_averages = np.array([1,3,6,9,12])\n",
        "stats = BregmanBenchmark(att_variance=n_average,\n",
        "                    attributes_distribution=attributes_distribution,\n",
        "                    weight_variance=1,\n",
        "                    weight_distribution=weight_distribution,\n",
        "                    edge_distribution=edge_distribution,\n",
        "                    run_torch=False\n",
        "                 )\\\n",
        "                  .run_2_5(n_average=n_average,\n",
        "                            cluster_sizes=sizes,\n",
        "                            b = 5,\n",
        "                            w_averages=w_averages,\n",
        "                            att_averages=att_averages)\n",
        "with open('test_2_5.pickle', 'wb') as handle:\n",
        "    pickle.dump(stats, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "!cp \"/content/test_2_5.pickle\" \"/content/drive/MyDrive\""
      ],
      "metadata": {
        "id": "Zpr5g5JCzEkG"
      },
      "id": "Zpr5g5JCzEkG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_2_5=None\n",
        "with open(\"/content/drive/MyDrive/test_2_5.pickle\", 'rb') as handle:\n",
        "    test_2_5 = pickle.load(handle)\n",
        "test_2_5.keys()\n",
        "df = pd.DataFrame.from_dict(test_2_5)\n",
        "# labels = [ 'EM-GMM', 'SC', 'Algo1', 'attSBM','IR_sLS']\n",
        "# algos = [\"attributes\", \"graph\", \"ours\", \"attSBM\", \"IR_sLS\"]\n",
        "# saveFig = True\n",
        "# for varying in [\"graph\",\"attributes\"]:\n",
        "#   curves = []\n",
        "#   curves_std = []\n",
        "#   for algo in algos:\n",
        "#     curves.append(df.loc[(df['varying'] == varying) & (df['algorithm'] == algo)][\"ARI\"])\n",
        "#     curves_std.append(df.loc[(df['varying'] == varying) & (df['algorithm'] == algo)][\"ARI_std\"])\n",
        "#   if varying == 'graph':\n",
        "#     x = df.loc[(df['varying'] == \"graph\")][\"weights_avg\"].unique()\n",
        "#     fileName = 'N_' + str(n) + '_K_' + str(n_clusters) + '_att_' + str(2)  +  '_nAverage' + str(n_average) + '.jpeg'\n",
        "#     plotting( x, curves, labels, curves_std = curves_std, xticks = x, xlabel = 'weights_avg', saveFig = True, fileName = fileName )\n",
        "#     plt.close()\n",
        "#   elif varying == 'attributes':\n",
        "#     x = df.loc[(df['varying'] == \"attributes\")][\"attributes_avg\"].unique()\n",
        "#     fileName = 'N_' + str(n) + '_K_' + str(n_clusters) + '_w_' + str(2) + '_nAverage_' + str(n_average) + '.jpeg'\n",
        "#     plotting( x , curves, labels, curves_std = curves_std, xticks = x, xlabel = 'attributes_avg', saveFig = True, fileName = fileName )\n",
        "#     plt.close()"
      ],
      "metadata": {
        "id": "HROKJI17kQ-y"
      },
      "id": "HROKJI17kQ-y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Real Data"
      ],
      "metadata": {
        "id": "BCvSIxvhmD5j"
      },
      "id": "BCvSIxvhmD5j"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7942ed30",
      "metadata": {
        "id": "7942ed30"
      },
      "outputs": [],
      "source": [
        "attributes_distribution = \"gaussian\"\n",
        "edge_distribution = \"bernoulli\"\n",
        "weight_distribution = \"gaussian\"\n",
        "benchmark = BregmanBenchmark(att_variance=1,\n",
        "                    attributes_distribution=attributes_distribution,\n",
        "                    weight_variance=1,\n",
        "                    weight_distribution=weight_distribution,\n",
        "                    edge_distribution=edge_distribution,\n",
        "                    run_torch=False,\n",
        "                    initializer = 'AIC',\n",
        "                    hard_clustering=True)\n",
        "scores = benchmark.run_real_data(strategy=3,n_iters=100,reduction_method=\"UMAP\")\n",
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(scores)"
      ],
      "metadata": {
        "id": "qEpRHoNLQeqd"
      },
      "id": "qEpRHoNLQeqd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Using strategy 3:\n",
        "\n",
        "25 runs\n",
        "{'dataset': ['Cornell', 'Texas', 'Wisconsin', 'Cora', 'CiteSeer'],\n",
        " 'ARI': [0.021333077187108966,\n",
        "  0.02158094558247706,\n",
        "  0.06561886114111304,\n",
        "  0.09454483715306834,\n",
        "  0.021826025060071436]}\n",
        "\n",
        "100 runs\n",
        "{'dataset': ['Cornell', 'Texas', 'Wisconsin', 'Cora', 'CiteSeer'],\n",
        " 'ARI': [-0.00813056323456639,\n",
        "  0.020549452476684223,\n",
        "  0.06253016110148793,\n",
        "  0.174525709285103,\n",
        "  0.022005394987926818]}\n",
        "\n",
        "Using strategy 0:\n",
        "\n",
        "25runs\n",
        "{'dataset': ['Cornell', 'Texas', 'Wisconsin', 'Cora', 'CiteSeer'],\n",
        " 'ARI': [0.0020494127978944623,\n",
        "  0.021389147279564147,\n",
        "  0.04300891147648944,\n",
        "  -0.00330201159364617,\n",
        "  0.25845609477298936]}\n",
        "\n",
        "100 runs\n",
        "{'dataset': ['Cornell', 'Texas', 'Wisconsin', 'Cora', 'CiteSeer'],\n",
        " 'ARI': [0.008127656067387532,\n",
        "  0.023515852562689822,\n",
        "  0.06482587767403367,\n",
        "  0.0248570289631233,\n",
        "  0.021949234040387094]}\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "9StId__H-ZD0"
      },
      "id": "9StId__H-ZD0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UJ_dbuJWeAn8",
      "metadata": {
        "id": "UJ_dbuJWeAn8"
      },
      "outputs": [],
      "source": [
        "# attributes_distribution = \"gaussian\"\n",
        "# edge_distribution = \"bernoulli\"\n",
        "# weight_distribution = \"exponential\"\n",
        "# BregmanBenchmark(att_variance=1,\n",
        "#                     attributes_distribution=attributes_distribution,\n",
        "#                     weight_variance=1,\n",
        "#                     weight_distribution=weight_distribution,\n",
        "#                     edge_distribution=edge_distribution,\n",
        "#                     run_torch=False)\\\n",
        "#                  .run_test(n_average=n_average,cluster_sizes=sizes,\\\n",
        "#                  b=5,\\\n",
        "#                  a_range=[ 5,7,9,11,13,15 ],\\\n",
        "#                  r_range = [ 0,1,2,3,4,5 ],\\\n",
        "#                  dense=False,\\\n",
        "#                  binary=True,\\\n",
        "#                  file_endings=\".jpeg\",\\\n",
        "#                  n_iters=25)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Begin Plots"
      ],
      "metadata": {
        "id": "7rU3bGnAmO8n"
      },
      "id": "7rU3bGnAmO8n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f1ZvaasK7XH",
      "metadata": {
        "id": "8f1ZvaasK7XH"
      },
      "outputs": [],
      "source": [
        "from BregmanTests.utils import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3vN0pwvtM-Eo",
      "metadata": {
        "id": "3vN0pwvtM-Eo"
      },
      "outputs": [],
      "source": [
        "test_2_1=None\n",
        "with open(\"/content/drive/MyDrive/test_2_1.pickle\", 'rb') as handle:\n",
        "    test_2_1 = pickle.load(handle)\n",
        "test_2_1.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TrkQZoOAQae4",
      "metadata": {
        "id": "TrkQZoOAQae4"
      },
      "outputs": [],
      "source": [
        "scatter_(test_2_1,'a', 'r', 'ARI')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QY5bJiRenKe8",
      "metadata": {
        "id": "QY5bJiRenKe8"
      },
      "outputs": [],
      "source": [
        "scatter_with_colorbar(test_2_1,'a', 'r', 'ARI')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_2_4=None\n",
        "SIZE_TITLE = 24\n",
        "SIZE_LABELS = 24\n",
        "SIZE_TICKS = 18\n",
        "SIZE_LEGEND = 18\n",
        "with open(\"/content/drive/MyDrive/test_2_4.pickle\", 'rb') as handle:\n",
        "    test_2_4 = pickle.load(handle)\n",
        "fig = plt.figure(figsize=(5, 4))\n",
        "ax = fig.add_subplot(111)\n",
        "x,y,z = np.array(test_2_4[\"lambda_att\"]),np.array(test_2_4[\"lambda_w\"]),np.array(test_2_4[\"ARI\"])\n",
        "xlabel=\"attributes_avg\"\n",
        "ylabel=\"weights_avg\"\n",
        "C = ax.scatter(x=1/x,y=1/y,c=z,cmap=\"coolwarm\")\n",
        "plt.ylim(0.9,3.5)\n",
        "ticks = np.linspace(z.min(), z.max(), 5, endpoint=True)\n",
        "cb = fig.colorbar(C, ax=ax, fraction=0.02, pad=0.1, label='ARI',ticks=ticks)\n",
        "cb.set_label(label='ARI', size=SIZE_LEGEND)\n",
        "cb.ax.tick_params(labelsize=SIZE_TICKS)\n",
        "plt.xlabel( xlabel, fontsize = SIZE_LABELS )\n",
        "plt.ylabel( ylabel, fontsize = SIZE_LABELS )\n",
        "plt.xticks( fontsize = SIZE_TICKS )\n",
        "plt.yticks( fontsize = SIZE_TICKS )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wBuJ9YmNZqUu"
      },
      "id": "wBuJ9YmNZqUu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B8LRjwn2N3ja",
      "metadata": {
        "id": "B8LRjwn2N3ja"
      },
      "outputs": [],
      "source": [
        "x,y,z = test_2_1[\"a\"],test_2_1[\"r\"],test_2_1[\"ARI\"]\n",
        "vals_x = np.unique(x)\n",
        "vals_y = np.unique(y)\n",
        "\"\"\"\n",
        "len(X) == N is the number of columns in Z and len(Y) == M is the number of rows in Z.\n",
        "Z = M x N\n",
        "\"\"\"\n",
        "x = np.array(x).reshape(vals_x.shape[0],vals_y.shape[0])\n",
        "y = np.array(y).reshape(vals_x.shape[0],vals_y.shape[0])\n",
        "z = np.array(z).reshape(vals_x.shape[0],vals_y.shape[0]).T\n",
        "make_contour_plot(vals_x,vals_y,z,x_label=\"a\",y_label=\"r\",filename=\"contour_plot_2_1.jpeg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GzYD-jJYV6h4",
      "metadata": {
        "id": "GzYD-jJYV6h4"
      },
      "outputs": [],
      "source": [
        "test_2_2=None\n",
        "with open(\"/content/drive/MyDrive/test_2_2.pickle\", 'rb') as handle:\n",
        "    test_2_2 = pickle.load(handle)\n",
        "test_2_2.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OF2FxOgcV9Fp",
      "metadata": {
        "id": "OF2FxOgcV9Fp"
      },
      "outputs": [],
      "source": [
        "scatter_(test_2_2,'d', 'mu', 'ARI')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HcgfbcQMYA7-",
      "metadata": {
        "id": "HcgfbcQMYA7-"
      },
      "outputs": [],
      "source": [
        "x,y,z = test_2_2[\"d\"],test_2_2[\"mu\"],test_2_2[\"ARI\"]\n",
        "vals_x = np.unique(x)\n",
        "vals_y = np.unique(y)\n",
        "\"\"\"\n",
        "len(X) == N is the number of columns in Z and len(Y) == M is the number of rows in Z.\n",
        "Z = M x N\n",
        "\"\"\"\n",
        "x = np.array(x).reshape(vals_x.shape[0],vals_y.shape[0])\n",
        "y = np.array(y).reshape(vals_x.shape[0],vals_y.shape[0])\n",
        "# x,y = np.meshgrid(vals_x,vals_y)\n",
        "z = np.array(z).reshape(len(vals_x),len(vals_y)).T\n",
        "make_contour_plot(vals_x,vals_y,z,x_label=\"d\",y_label=\"mu\",filename=\"contour_plot_2_2.jpeg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tKwys6pKYU31",
      "metadata": {
        "id": "tKwys6pKYU31"
      },
      "outputs": [],
      "source": [
        "test_2_3=None\n",
        "with open(\"/content/drive/MyDrive/test_2_3.pickle\", 'rb') as handle:\n",
        "    test_2_3 = pickle.load(handle)\n",
        "test_2_3.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1Dk3He9t3kkn",
      "metadata": {
        "id": "1Dk3He9t3kkn"
      },
      "outputs": [],
      "source": [
        "x,y,z,data = test_2_3[\"d\"],test_2_3[\"lambda\"], test_2_3[\"a\"],test_2_3[\"ARI\"]\n",
        "vals_x = np.unique(x)\n",
        "vals_y = np.unique(y)\n",
        "vals_z = np.unique(z)\n",
        "\"\"\"\n",
        "len(X) == N is the number of columns in data,\n",
        "len(Y) == M is the number of rows in data.\n",
        "len(Z) == P is the depth of data\n",
        "DATA = M x N X P\n",
        "\"\"\"\n",
        "X = np.array(x).reshape(vals_x.shape[0],vals_y.shape[0],vals_z.shape[0])\n",
        "Y = np.array(y).reshape(vals_x.shape[0],vals_y.shape[0],vals_z.shape[0])\n",
        "Z = np.array(z).reshape(vals_x.shape[0],vals_y.shape[0],vals_z.shape[0])\n",
        "data = np.array(data).reshape(vals_x.shape[0],vals_y.shape[0],vals_z.shape[0])\n",
        "x_label=\"d\"\n",
        "y_label=\"lambda\"\n",
        "z_label = \"a\"\n",
        "\n",
        "kw = {\n",
        "        # 'vmin': data.min(),\n",
        "        # 'vmax': data.max()\n",
        "    }\n",
        "\n",
        "# Create a figure with 3D ax\n",
        "fig = plt.figure(figsize=(5, 4))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Set limits of the plot from coord limits\n",
        "xmin, xmax = X.min(), X.max()\n",
        "ymin, ymax = Y.min(), Y.max()\n",
        "zmin, zmax = Z.min(), Z.max()\n",
        "ax.set(xlim=[xmin, xmax], ylim=[ymin, ymax], zlim=[zmin, zmax])\n",
        "\n",
        "# Plot contour surfaces\n",
        "    ### This is the X x Y plane for z=zmax\n",
        "_ = ax.contourf(\n",
        "            X[:, :, -1], Y[:, :, -1], data[:, :, -1],\n",
        "            zdir='z', offset=zmax, **kw\n",
        "        )\n",
        "\n",
        "    ### This is the X x Y plane for z=zmin\n",
        "_ = ax.contourf(\n",
        "            X[:, :, 0], Y[:, :, 0], data[:, :, 0],\n",
        "            zdir='z', offset=zmin, **kw\n",
        "        )\n",
        "\n",
        "    ### This is the X x Z plane for y=ymax\n",
        "_ = ax.contourf(\n",
        "            X[-1, :, :], data[-1, :, :], Z[-1, :, :],\n",
        "            zdir='y', offset=ymax, **kw\n",
        "        )\n",
        "\n",
        "    ### This is the X x Z plane for y=ymin\n",
        "_ = ax.contourf(\n",
        "            X[0, :, :], data[0, :, :], Z[0, :, :],\n",
        "            zdir='y', offset=ymin, **kw\n",
        "        )\n",
        "\n",
        "    ### This is the Y x Z plane for x=xmax\n",
        "_ = ax.contourf(\n",
        "            data[:, -1, :], Y[:, -1, :], Z[:, -1, :],\n",
        "            zdir='x', offset=xmax, **kw\n",
        "        )\n",
        "\n",
        "    ### This is the Y x Z plane for x=xmin\n",
        "C = ax.contourf(\n",
        "            data[:, 0, :], Y[:, 0, :], Z[:, 0, :],\n",
        "            zdir='x', offset=xmin, **kw\n",
        "        )\n",
        "\n",
        "\n",
        "# Plot edges\n",
        "edges_kw = dict(color='0.4', linewidth=1,zorder=-1e3)\n",
        "ax.plot([xmax, xmax], [ymin, ymax], zmin, **edges_kw)\n",
        "ax.plot([xmin, xmax], [ymin, ymin], zmin, **edges_kw)\n",
        "ax.plot([xmin, xmax], [ymin, ymin], [zmin, zmax], **edges_kw)\n",
        "\n",
        "# Set labels and zticks\n",
        "ax.set(\n",
        "        xlabel=x_label,\n",
        "        ylabel=y_label,\n",
        "        zlabel=z_label\n",
        "    )\n",
        "\n",
        "# Set zoom and angle view\n",
        "ax.view_init(30, 45, 0)\n",
        "ax.set_box_aspect(None, zoom=0.9)\n",
        "\n",
        "# Colorbar\n",
        "fig.colorbar(C, ax=ax, fraction=0.02, pad=0.1, label='ARI')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "N2yOg0zK6osd",
      "metadata": {
        "id": "N2yOg0zK6osd"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(5, 4))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.set(\n",
        "        xlabel=x_label,\n",
        "        ylabel=y_label,\n",
        "        zlabel=z_label\n",
        "    )\n",
        "C = ax.scatter(xs=X,ys=Y,zs=Z,c=data)\n",
        "fig.colorbar(C, ax=ax, fraction=0.02, pad=0.2, label='ARI')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}