{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "jP3HrzLaFCl0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jP3HrzLaFCl0",
        "outputId": "1a5774b3-73f7-4037-bacc-48fec246d711"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "wqMKN-tSMM0L",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqMKN-tSMM0L",
        "outputId": "b350b27b-bb1e-4c46-e529-9b930e88f641"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/FelipeSchreiber/BregmanClustering.git\n",
            "  Cloning https://github.com/FelipeSchreiber/BregmanClustering.git to /tmp/pip-req-build-99lr_ux6\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/FelipeSchreiber/BregmanClustering.git /tmp/pip-req-build-99lr_ux6\n",
            "  Resolved https://github.com/FelipeSchreiber/BregmanClustering.git to commit af24f20d37e484297f4abfa5e9f4d237ace2f0db\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: bregClust\n",
            "  Building wheel for bregClust (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bregClust: filename=bregClust-1.0-py3-none-any.whl size=35039 sha256=013e64467003c6ab1eec2ee34399a816361f03a0a2086fabf10a69aa7d6af1c0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jc1ufz8y/wheels/3f/90/fb/833529540c1d5f19c385fde761cc07c664c4b9a5edf7c6735b\n",
            "Successfully built bregClust\n",
            "Installing collected packages: bregClust\n",
            "  Attempting uninstall: bregClust\n",
            "    Found existing installation: bregClust 1.0\n",
            "    Uninstalling bregClust-1.0:\n",
            "      Successfully uninstalled bregClust-1.0\n",
            "Successfully installed bregClust-1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.3.1)\n",
            "Requirement already satisfied: rpy2==3.5.1 in /usr/local/lib/python3.10/dist-packages (3.5.1)\n",
            "Requirement already satisfied: cffi>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from rpy2==3.5.1) (1.15.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from rpy2==3.5.1) (3.1.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from rpy2==3.5.1) (2022.7.1)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from rpy2==3.5.1) (4.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.27.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.10.0->rpy2==3.5.1) (2.21)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->rpy2==3.5.1) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
            "Requirement already satisfied: pytz-deprecation-shim in /usr/local/lib/python3.10/dist-packages (from tzlocal->rpy2==3.5.1) (0.1.0.post0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.10/dist-packages (from pytz-deprecation-shim->tzlocal->rpy2==3.5.1) (2023.3)\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall git+https://github.com/FelipeSchreiber/BregmanClustering.git --no-deps\n",
        "!pip install torch_geometric rpy2==3.5.1\n",
        "import os\n",
        "import pickle\n",
        "from sys import platform\n",
        "import BregmanTests\n",
        "os.chmod(BregmanTests.__path__[0]+\"/install_algos.sh\",777)\n",
        "if platform == \"win32\":\n",
        "    os.environ[\"R_HOME\"] = r\"C:\\\\Program Files\\R\\R-4.2.3\"\n",
        "else:\n",
        "    ### Uncomment line below if in Google Colab environment\n",
        "    print(os.path.isfile(BregmanTests.__path__[0]+\"/install_algos.sh\"))\n",
        "    ### Done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4w2gsGfqMbhn",
      "metadata": {
        "id": "4w2gsGfqMbhn"
      },
      "outputs": [],
      "source": [
        "from BregmanTests.benchmark import *\n",
        "n_average = 20\n",
        "n = 600\n",
        "n_clusters = 2\n",
        "d = 1\n",
        "sizes = [ n // n_clusters ]*np.ones( n_clusters, dtype = int )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test 2_1"
      ],
      "metadata": {
        "id": "4oK8WTsVlLci"
      },
      "id": "4oK8WTsVlLci"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run numpy model"
      ],
      "metadata": {
        "id": "bSqHh5mkgtYf"
      },
      "id": "bSqHh5mkgtYf"
    },
    {
      "cell_type": "code",
      "source": [
        "attributes_distribution = \"gaussian\"\n",
        "edge_distribution = \"bernoulli\"\n",
        "weight_distribution = \"exponential\"\n",
        "a_range = np.linspace(5,14,3)\n",
        "r_range = np.linspace(0,0.7,3)*np.log(n)\n",
        "stats = BregmanBenchmark(att_variance=1,\n",
        "                    attributes_distribution=attributes_distribution,\n",
        "                    weight_variance=1,\n",
        "                    weight_distribution=weight_distribution,\n",
        "                    edge_distribution=edge_distribution,\n",
        "                    run_torch=False,\n",
        "                    initializer = 'AIC')\\\n",
        "                  .run_2_1(n_average=1,\n",
        "                            cluster_sizes=sizes,\n",
        "                            b=5,\n",
        "                            a_range= a_range,\n",
        "                            r_range = r_range,\n",
        "                            dense=False,\n",
        "                            binary=True)\n",
        "with open('test_2_1.pickle', 'wb') as handle:\n",
        "    pickle.dump(stats, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "!cp \"/content/test_2_1.pickle\" \"/content/drive/MyDrive\""
      ],
      "metadata": {
        "id": "v4iSOddDO2qs",
        "outputId": "fc0fd0f9-8836-49c5-86d9-0909e3fdbbaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "v4iSOddDO2qs",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:21, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-f5f4f1181a8d>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ma_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mr_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m stats = BregmanBenchmark(att_variance=1,\n\u001b[0m\u001b[1;32m      7\u001b[0m                     \u001b[0mattributes_distribution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattributes_distribution\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mweight_variance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/BregmanTests/benchmark.py\u001b[0m in \u001b[0;36mrun_2_1\u001b[0;34m(self, n_average, cluster_sizes, b, a_range, r_range, dense, binary, n_iters)\u001b[0m\n\u001b[1;32m    395\u001b[0m                     \u001b[0mz_pred_both\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgraph_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m                     \u001b[0mz_pred_both\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m                 \u001b[0maris_both\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0madjusted_rand_score\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mz_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_pred_both\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m                 \u001b[0maris_both_mean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0maris_both\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/BregmanClustering/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, A, X, Y, Z_init)\u001b[0m\n\u001b[1;32m   1107\u001b[0m             \u001b[0mZ_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE_projection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM_projection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZ_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m             \u001b[0mconvergence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicted_memberships\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZ_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1110\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicted_memberships\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/BregmanClustering/models.py\u001b[0m in \u001b[0;36mstop_criterion\u001b[0;34m(self, A, X, Y, Z_old, Z_new, iteration)\u001b[0m\n\u001b[1;32m   1071\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstop_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZ_old\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZ_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m         \u001b[0mold_log_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZ_old\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m         \u001b[0mnew_log_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZ_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1074\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_log_prob\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnew_log_prob\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/BregmanClustering/models.py\u001b[0m in \u001b[0;36mlogprob\u001b[0;34m(self, A, X, Y, Z)\u001b[0m\n\u001b[1;32m   1064\u001b[0m             \u001b[0mprob_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m                 \u001b[0mtotal_div\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputeTotalDiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1067\u001b[0m                 \u001b[0mprob_i\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunities_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtotal_div\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m             \u001b[0mlog_prob_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/BregmanClustering/models.py\u001b[0m in \u001b[0;36mcomputeTotalDiv\u001b[0;34m(self, node, q, A, X, Z, H)\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0medge_div\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_indices_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m             edge_div += np.sum( paired_distances(X[node,v_indices_out,:],\\\n\u001b[0m\u001b[1;32m   1034\u001b[0m                                                  E[q,z_t[v_indices_out],:],metric=self.weight_divergence) )\n\u001b[1;32m   1035\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_indices_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpaired_distances\u001b[0;34m(X, Y, metric, **kwds)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;31m# Check the matrix first (it is usually done by the metric)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_paired_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcheck_paired_arrays\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mIf\u001b[0m \u001b[0mY\u001b[0m \u001b[0mwas\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_Y\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpointer\u001b[0m \u001b[0mto\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \"\"\"\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         )\n\u001b[0;32m--> 163\u001b[0;31m         Y = check_array(\n\u001b[0m\u001b[1;32m    164\u001b[0m             \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains NaN."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run torch model"
      ],
      "metadata": {
        "id": "w_rMJxzygfZl"
      },
      "id": "w_rMJxzygfZl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1QGRHlHVMvL4",
      "metadata": {
        "id": "1QGRHlHVMvL4"
      },
      "outputs": [],
      "source": [
        "attributes_distribution = \"gaussian\"\n",
        "edge_distribution = \"bernoulli\"\n",
        "weight_distribution = \"exponential\"\n",
        "a_range = np.linspace(5,14,3)\n",
        "r_range = np.linspace(0,0.7,3)*np.log(n)\n",
        "stats = BregmanBenchmark(att_variance=1,\n",
        "                    attributes_distribution=attributes_distribution,\n",
        "                    weight_variance=1,\n",
        "                    weight_distribution=weight_distribution,\n",
        "                    edge_distribution=edge_distribution,\n",
        "                    run_torch=True,\n",
        "                    initializer = 'chernoff')\\\n",
        "                  .run_2_1(n_average=1,\n",
        "                            cluster_sizes=sizes,\n",
        "                            b=5,\n",
        "                            a_range= a_range,\n",
        "                            r_range = r_range,\n",
        "                            dense=False,\n",
        "                            binary=True)\n",
        "with open('test_2_1.pickle', 'wb') as handle:\n",
        "    pickle.dump(stats, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "!cp \"/content/test_2_1.pickle\" \"/content/drive/MyDrive\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test 2_2"
      ],
      "metadata": {
        "id": "VVVPpsn8l01D"
      },
      "id": "VVVPpsn8l01D"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XYNgyTRXEhrK",
      "metadata": {
        "id": "XYNgyTRXEhrK"
      },
      "outputs": [],
      "source": [
        "attributes_distribution = \"poisson\"\n",
        "edge_distribution = \"bernoulli\"\n",
        "weight_distribution = \"gaussian\"\n",
        "d_range = np.arange(1,6)\n",
        "mu_range = np.linspace(0,6,20)\n",
        "att_centers = np.arange(1,4).reshape(-1,1)\n",
        "stats = BregmanBenchmark(att_variance=1,\n",
        "                    attributes_distribution=attributes_distribution,\n",
        "                    weight_variance=1,\n",
        "                    weight_distribution=weight_distribution,\n",
        "                    edge_distribution=edge_distribution,\n",
        "                    att_centers=att_centers,\n",
        "                    run_torch=False\n",
        "                  )\\\n",
        "                  .run_2_2(n_average=10,\n",
        "                            cluster_sizes=sizes,\n",
        "                             d_range = d_range,\n",
        "                             mu_range = mu_range,\n",
        "                             dense=True,\n",
        "                             binary=False)\n",
        "with open('test_2_2.pickle', 'wb') as handle:\n",
        "    pickle.dump(stats, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "!cp \"/content/test_2_2.pickle\" \"/content/drive/MyDrive\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test 2_3"
      ],
      "metadata": {
        "id": "XlpxvjqBlt3q"
      },
      "id": "XlpxvjqBlt3q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GdUwRBlstRH-",
      "metadata": {
        "id": "GdUwRBlstRH-"
      },
      "outputs": [],
      "source": [
        "attributes_distribution = \"poisson\"\n",
        "edge_distribution = \"bernoulli\"\n",
        "weight_distribution = \"exponential\"\n",
        "d_range = np.arange(1,5)\n",
        "a_range = np.linspace(5,14,10)\n",
        "lambda_range = np.arange(1,6)\n",
        "att_centers = np.arange(1,4).reshape(-1,1)\n",
        "stats = BregmanBenchmark(att_variance=1,\n",
        "                    attributes_distribution=attributes_distribution,\n",
        "                    weight_variance=1,\n",
        "                    weight_distribution=weight_distribution,\n",
        "                    edge_distribution=edge_distribution,\n",
        "                    att_centers=att_centers,\n",
        "                    run_torch=False\n",
        "                 )\\\n",
        "                  .run_2_3(n_average=10,\n",
        "                            cluster_sizes=sizes,\n",
        "                            d_range= d_range,\n",
        "                            lambda_range = lambda_range,\n",
        "                            a_range = a_range,\n",
        "                            b = 5,\n",
        "                            dense=False,\n",
        "                            binary=False)\n",
        "with open('test_2_3.pickle', 'wb') as handle:\n",
        "    pickle.dump(stats, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "!cp \"/content/test_2_3.pickle\" \"/content/drive/MyDrive\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test 2_4"
      ],
      "metadata": {
        "id": "HcYf4xKeleyK"
      },
      "id": "HcYf4xKeleyK"
    },
    {
      "cell_type": "code",
      "source": [
        "attributes_distribution = \"exponential\"\n",
        "edge_distribution = \"bernoulli\"\n",
        "weight_distribution = \"exponential\"\n",
        "att_averages = np.linspace(1,5,10)\n",
        "w_averages = np.linspace(1,5,10)\n",
        "stats = BregmanBenchmark(att_variance=1,\n",
        "                    attributes_distribution=attributes_distribution,\n",
        "                    weight_variance=1,\n",
        "                    weight_distribution=weight_distribution,\n",
        "                    edge_distribution=edge_distribution,\n",
        "                    run_torch=False\n",
        "                 )\\\n",
        "                  .run_2_4(n_average=10,\n",
        "                            cluster_sizes=sizes,\n",
        "                            b = 5,\n",
        "                            w_averages=w_averages,\n",
        "                            att_averages=att_averages)\n",
        "with open('test_2_4.pickle', 'wb') as handle:\n",
        "    pickle.dump(stats, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "!cp \"/content/test_2_4.pickle\" \"/content/drive/MyDrive\""
      ],
      "metadata": {
        "id": "isj4xK4sGdg9"
      },
      "id": "isj4xK4sGdg9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test 2_5"
      ],
      "metadata": {
        "id": "JWvoW4tklTOT"
      },
      "id": "JWvoW4tklTOT"
    },
    {
      "cell_type": "code",
      "source": [
        "attributes_distribution = \"exponential\"\n",
        "edge_distribution = \"bernoulli\"\n",
        "weight_distribution = \"exponential\"\n",
        "att_averages = np.linspace(1,5,5)\n",
        "w_averages = np.array([1,3,6,9,12])\n",
        "stats = BregmanBenchmark(att_variance=n_average,\n",
        "                    attributes_distribution=attributes_distribution,\n",
        "                    weight_variance=1,\n",
        "                    weight_distribution=weight_distribution,\n",
        "                    edge_distribution=edge_distribution,\n",
        "                    run_torch=False\n",
        "                 )\\\n",
        "                  .run_2_5(n_average=n_average,\n",
        "                            cluster_sizes=sizes,\n",
        "                            b = 5,\n",
        "                            w_averages=w_averages,\n",
        "                            att_averages=att_averages)\n",
        "with open('test_2_5.pickle', 'wb') as handle:\n",
        "    pickle.dump(stats, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "!cp \"/content/test_2_5.pickle\" \"/content/drive/MyDrive\""
      ],
      "metadata": {
        "id": "Zpr5g5JCzEkG"
      },
      "id": "Zpr5g5JCzEkG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_2_5=None\n",
        "with open(\"/content/drive/MyDrive/test_2_5.pickle\", 'rb') as handle:\n",
        "    test_2_5 = pickle.load(handle)\n",
        "test_2_5.keys()\n",
        "df = pd.DataFrame.from_dict(test_2_5)\n",
        "# labels = [ 'EM-GMM', 'SC', 'Algo1', 'attSBM','IR_sLS']\n",
        "# algos = [\"attributes\", \"graph\", \"ours\", \"attSBM\", \"IR_sLS\"]\n",
        "# saveFig = True\n",
        "# for varying in [\"graph\",\"attributes\"]:\n",
        "#   curves = []\n",
        "#   curves_std = []\n",
        "#   for algo in algos:\n",
        "#     curves.append(df.loc[(df['varying'] == varying) & (df['algorithm'] == algo)][\"ARI\"])\n",
        "#     curves_std.append(df.loc[(df['varying'] == varying) & (df['algorithm'] == algo)][\"ARI_std\"])\n",
        "#   if varying == 'graph':\n",
        "#     x = df.loc[(df['varying'] == \"graph\")][\"weights_avg\"].unique()    \n",
        "#     fileName = 'N_' + str(n) + '_K_' + str(n_clusters) + '_att_' + str(2)  +  '_nAverage' + str(n_average) + '.jpeg'\n",
        "#     plotting( x, curves, labels, curves_std = curves_std, xticks = x, xlabel = 'weights_avg', saveFig = True, fileName = fileName )\n",
        "#     plt.close()\n",
        "#   elif varying == 'attributes':\n",
        "#     x = df.loc[(df['varying'] == \"attributes\")][\"attributes_avg\"].unique()\n",
        "#     fileName = 'N_' + str(n) + '_K_' + str(n_clusters) + '_w_' + str(2) + '_nAverage_' + str(n_average) + '.jpeg'\n",
        "#     plotting( x , curves, labels, curves_std = curves_std, xticks = x, xlabel = 'attributes_avg', saveFig = True, fileName = fileName )\n",
        "#     plt.close()"
      ],
      "metadata": {
        "id": "HROKJI17kQ-y"
      },
      "id": "HROKJI17kQ-y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Real Data"
      ],
      "metadata": {
        "id": "BCvSIxvhmD5j"
      },
      "id": "BCvSIxvhmD5j"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7942ed30",
      "metadata": {
        "id": "7942ed30"
      },
      "outputs": [],
      "source": [
        "attributes_distribution = \"bernoulli\"\n",
        "edge_distribution = \"bernoulli\"\n",
        "weight_distribution = \"gaussian\"\n",
        "scores = BregmanBenchmark(att_variance=1,\n",
        "                    attributes_distribution=attributes_distribution,\n",
        "                    weight_variance=1,\n",
        "                    weight_distribution=weight_distribution,\n",
        "                    edge_distribution=edge_distribution,\n",
        "                    run_torch=False)\\\n",
        "                  .run_real_data()\n",
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UJ_dbuJWeAn8",
      "metadata": {
        "id": "UJ_dbuJWeAn8"
      },
      "outputs": [],
      "source": [
        "# attributes_distribution = \"gaussian\"\n",
        "# edge_distribution = \"bernoulli\"\n",
        "# weight_distribution = \"exponential\"\n",
        "# BregmanBenchmark(att_variance=1,\n",
        "#                     attributes_distribution=attributes_distribution,\n",
        "#                     weight_variance=1,\n",
        "#                     weight_distribution=weight_distribution,\n",
        "#                     edge_distribution=edge_distribution,\n",
        "#                     run_torch=False)\\\n",
        "#                  .run_test(n_average=n_average,cluster_sizes=sizes,\\\n",
        "#                  b=5,\\\n",
        "#                  a_range=[ 5,7,9,11,13,15 ],\\\n",
        "#                  r_range = [ 0,1,2,3,4,5 ],\\\n",
        "#                  dense=False,\\\n",
        "#                  binary=True,\\\n",
        "#                  file_endings=\".jpeg\",\\\n",
        "#                  n_iters=25)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Begin Plots"
      ],
      "metadata": {
        "id": "7rU3bGnAmO8n"
      },
      "id": "7rU3bGnAmO8n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f1ZvaasK7XH",
      "metadata": {
        "id": "8f1ZvaasK7XH"
      },
      "outputs": [],
      "source": [
        "from BregmanTests.utils import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3vN0pwvtM-Eo",
      "metadata": {
        "id": "3vN0pwvtM-Eo"
      },
      "outputs": [],
      "source": [
        "test_2_1=None\n",
        "with open(\"/content/drive/MyDrive/test_2_1.pickle\", 'rb') as handle:\n",
        "    test_2_1 = pickle.load(handle)\n",
        "test_2_1.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TrkQZoOAQae4",
      "metadata": {
        "id": "TrkQZoOAQae4"
      },
      "outputs": [],
      "source": [
        "def scatter_(dict_,x_name,y_name,z_name):\n",
        "  fig, ax = plt.subplots()\n",
        "  x,y = dict_[x_name],dict_[y_name]\n",
        "  ax.scatter(x,y)\n",
        "  for i, txt in enumerate(dict_[z_name]):\n",
        "      ax.annotate(\"{:.2f}\".format(txt), (x[i], y[i]))\n",
        "  ax.set_xlabel(x_name)\n",
        "  ax.set_ylabel(y_name)\n",
        "scatter_(test_2_1,'a', 'r', 'ARI')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QY5bJiRenKe8",
      "metadata": {
        "id": "QY5bJiRenKe8"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(5, 4))\n",
        "ax = fig.add_subplot(111)\n",
        "x,y,z = test_2_1[\"a\"],test_2_1[\"r\"],test_2_1[\"ARI\"]\n",
        "xlabel=\"a\"\n",
        "ylabel=\"r\"\n",
        "ticks = np.linspace(0, 1, 5, endpoint=True)\n",
        "C = ax.scatter(x=x,y=y,c=z,cmap=\"coolwarm\")\n",
        "cb = fig.colorbar(C, ax=ax, fraction=0.02, pad=0.1, label='ARI',ticks=ticks)\n",
        "cb.set_label(label='ARI', size=SIZE_LEGEND)\n",
        "cb.ax.tick_params(labelsize=SIZE_TICKS)\n",
        "plt.xlabel( xlabel, fontsize = SIZE_LABELS )\n",
        "plt.ylabel( ylabel, fontsize = SIZE_LABELS )\n",
        "plt.xticks( fontsize = SIZE_TICKS )\n",
        "plt.yticks( fontsize = SIZE_TICKS )\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_2_4=None\n",
        "SIZE_TITLE = 24\n",
        "SIZE_LABELS = 24\n",
        "SIZE_TICKS = 18\n",
        "SIZE_LEGEND = 18\n",
        "with open(\"/content/drive/MyDrive/test_2_4.pickle\", 'rb') as handle:\n",
        "    test_2_4 = pickle.load(handle)\n",
        "fig = plt.figure(figsize=(5, 4))\n",
        "ax = fig.add_subplot(111)\n",
        "x,y,z = np.array(test_2_4[\"lambda_att\"]),np.array(test_2_4[\"lambda_w\"]),np.array(test_2_4[\"ARI\"])\n",
        "xlabel=\"attributes_avg\"\n",
        "ylabel=\"weights_avg\"\n",
        "C = ax.scatter(x=1/x,y=1/y,c=z,cmap=\"coolwarm\")\n",
        "plt.ylim(0.9,3.5)\n",
        "ticks = np.linspace(z.min(), z.max(), 5, endpoint=True)\n",
        "cb = fig.colorbar(C, ax=ax, fraction=0.02, pad=0.1, label='ARI',ticks=ticks)\n",
        "cb.set_label(label='ARI', size=SIZE_LEGEND)\n",
        "cb.ax.tick_params(labelsize=SIZE_TICKS)\n",
        "plt.xlabel( xlabel, fontsize = SIZE_LABELS )\n",
        "plt.ylabel( ylabel, fontsize = SIZE_LABELS )\n",
        "plt.xticks( fontsize = SIZE_TICKS )\n",
        "plt.yticks( fontsize = SIZE_TICKS )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wBuJ9YmNZqUu"
      },
      "id": "wBuJ9YmNZqUu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B8LRjwn2N3ja",
      "metadata": {
        "id": "B8LRjwn2N3ja"
      },
      "outputs": [],
      "source": [
        "x,y,z = test_2_1[\"a\"],test_2_1[\"r\"],test_2_1[\"ARI\"]\n",
        "vals_x = np.unique(x)\n",
        "vals_y = np.unique(y)\n",
        "\"\"\"\n",
        "len(X) == N is the number of columns in Z and len(Y) == M is the number of rows in Z.\n",
        "Z = M x N\n",
        "\"\"\"\n",
        "x = np.array(x).reshape(vals_x.shape[0],vals_y.shape[0])\n",
        "y = np.array(y).reshape(vals_x.shape[0],vals_y.shape[0])\n",
        "z = np.array(z).reshape(vals_x.shape[0],vals_y.shape[0]).T\n",
        "make_contour_plot(vals_x,vals_y,z,x_label=\"a\",y_label=\"r\",filename=\"contour_plot_2_1.jpeg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GzYD-jJYV6h4",
      "metadata": {
        "id": "GzYD-jJYV6h4"
      },
      "outputs": [],
      "source": [
        "test_2_2=None\n",
        "with open(\"/content/drive/MyDrive/test_2_2.pickle\", 'rb') as handle:\n",
        "    test_2_2 = pickle.load(handle)\n",
        "test_2_2.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OF2FxOgcV9Fp",
      "metadata": {
        "id": "OF2FxOgcV9Fp"
      },
      "outputs": [],
      "source": [
        "scatter_(test_2_2,'d', 'mu', 'ARI')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HcgfbcQMYA7-",
      "metadata": {
        "id": "HcgfbcQMYA7-"
      },
      "outputs": [],
      "source": [
        "x,y,z = test_2_2[\"d\"],test_2_2[\"mu\"],test_2_2[\"ARI\"]\n",
        "vals_x = np.unique(x)\n",
        "vals_y = np.unique(y)\n",
        "\"\"\"\n",
        "len(X) == N is the number of columns in Z and len(Y) == M is the number of rows in Z.\n",
        "Z = M x N\n",
        "\"\"\"\n",
        "x = np.array(x).reshape(vals_x.shape[0],vals_y.shape[0])\n",
        "y = np.array(y).reshape(vals_x.shape[0],vals_y.shape[0])\n",
        "# x,y = np.meshgrid(vals_x,vals_y)\n",
        "z = np.array(z).reshape(len(vals_x),len(vals_y)).T\n",
        "make_contour_plot(vals_x,vals_y,z,x_label=\"d\",y_label=\"mu\",filename=\"contour_plot_2_2.jpeg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tKwys6pKYU31",
      "metadata": {
        "id": "tKwys6pKYU31"
      },
      "outputs": [],
      "source": [
        "test_2_3=None\n",
        "with open(\"/content/drive/MyDrive/test_2_3.pickle\", 'rb') as handle:\n",
        "    test_2_3 = pickle.load(handle)\n",
        "test_2_3.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1Dk3He9t3kkn",
      "metadata": {
        "id": "1Dk3He9t3kkn"
      },
      "outputs": [],
      "source": [
        "x,y,z,data = test_2_3[\"d\"],test_2_3[\"lambda\"], test_2_3[\"a\"],test_2_3[\"ARI\"]\n",
        "vals_x = np.unique(x)\n",
        "vals_y = np.unique(y)\n",
        "vals_z = np.unique(z)\n",
        "\"\"\"\n",
        "len(X) == N is the number of columns in data,\n",
        "len(Y) == M is the number of rows in data.\n",
        "len(Z) == P is the depth of data\n",
        "DATA = M x N X P\n",
        "\"\"\"\n",
        "X = np.array(x).reshape(vals_x.shape[0],vals_y.shape[0],vals_z.shape[0])\n",
        "Y = np.array(y).reshape(vals_x.shape[0],vals_y.shape[0],vals_z.shape[0])\n",
        "Z = np.array(z).reshape(vals_x.shape[0],vals_y.shape[0],vals_z.shape[0])\n",
        "data = np.array(data).reshape(vals_x.shape[0],vals_y.shape[0],vals_z.shape[0])\n",
        "x_label=\"d\"\n",
        "y_label=\"lambda\"\n",
        "z_label = \"a\"\n",
        "\n",
        "kw = {\n",
        "        # 'vmin': data.min(),\n",
        "        # 'vmax': data.max()\n",
        "    }\n",
        "\n",
        "# Create a figure with 3D ax\n",
        "fig = plt.figure(figsize=(5, 4))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Set limits of the plot from coord limits\n",
        "xmin, xmax = X.min(), X.max()\n",
        "ymin, ymax = Y.min(), Y.max()\n",
        "zmin, zmax = Z.min(), Z.max()\n",
        "ax.set(xlim=[xmin, xmax], ylim=[ymin, ymax], zlim=[zmin, zmax])\n",
        "\n",
        "# Plot contour surfaces\n",
        "    ### This is the X x Y plane for z=zmax \n",
        "_ = ax.contourf(\n",
        "            X[:, :, -1], Y[:, :, -1], data[:, :, -1],\n",
        "            zdir='z', offset=zmax, **kw\n",
        "        )\n",
        "    \n",
        "    ### This is the X x Y plane for z=zmin \n",
        "_ = ax.contourf(\n",
        "            X[:, :, 0], Y[:, :, 0], data[:, :, 0],\n",
        "            zdir='z', offset=zmin, **kw\n",
        "        )\n",
        "\n",
        "    ### This is the X x Z plane for y=ymax \n",
        "_ = ax.contourf(\n",
        "            X[-1, :, :], data[-1, :, :], Z[-1, :, :],\n",
        "            zdir='y', offset=ymax, **kw\n",
        "        )\n",
        "\n",
        "    ### This is the X x Z plane for y=ymin \n",
        "_ = ax.contourf(\n",
        "            X[0, :, :], data[0, :, :], Z[0, :, :],\n",
        "            zdir='y', offset=ymin, **kw\n",
        "        )\n",
        "\n",
        "    ### This is the Y x Z plane for x=xmax \n",
        "_ = ax.contourf(\n",
        "            data[:, -1, :], Y[:, -1, :], Z[:, -1, :],\n",
        "            zdir='x', offset=xmax, **kw\n",
        "        )\n",
        "\n",
        "    ### This is the Y x Z plane for x=xmin\n",
        "C = ax.contourf(\n",
        "            data[:, 0, :], Y[:, 0, :], Z[:, 0, :],\n",
        "            zdir='x', offset=xmin, **kw\n",
        "        )\n",
        "\n",
        "\n",
        "# Plot edges\n",
        "edges_kw = dict(color='0.4', linewidth=1,zorder=-1e3)\n",
        "ax.plot([xmax, xmax], [ymin, ymax], zmin, **edges_kw)\n",
        "ax.plot([xmin, xmax], [ymin, ymin], zmin, **edges_kw)\n",
        "ax.plot([xmin, xmax], [ymin, ymin], [zmin, zmax], **edges_kw)\n",
        "\n",
        "# Set labels and zticks\n",
        "ax.set(\n",
        "        xlabel=x_label,\n",
        "        ylabel=y_label,\n",
        "        zlabel=z_label\n",
        "    )\n",
        "\n",
        "# Set zoom and angle view\n",
        "ax.view_init(30, 45, 0)\n",
        "ax.set_box_aspect(None, zoom=0.9)\n",
        "\n",
        "# Colorbar\n",
        "fig.colorbar(C, ax=ax, fraction=0.02, pad=0.1, label='ARI')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "N2yOg0zK6osd",
      "metadata": {
        "id": "N2yOg0zK6osd"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(5, 4))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.set(\n",
        "        xlabel=x_label,\n",
        "        ylabel=y_label,\n",
        "        zlabel=z_label\n",
        "    )\n",
        "C = ax.scatter(xs=X,ys=Y,zs=Z,c=data)\n",
        "fig.colorbar(C, ax=ax, fraction=0.02, pad=0.2, label='ARI')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}