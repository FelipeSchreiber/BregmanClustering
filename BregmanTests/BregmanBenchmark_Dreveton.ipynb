{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "fb0e707d",
      "metadata": {
        "id": "fb0e707d",
        "outputId": "565ae028-b9dd-4e0b-c24b-95bbbf53fbdc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/FelipeSchreiber/BregmanClustering.git\n",
            "  Cloning https://github.com/FelipeSchreiber/BregmanClustering.git to /tmp/pip-req-build-yzl7mo06\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/FelipeSchreiber/BregmanClustering.git /tmp/pip-req-build-yzl7mo06\n",
            "  Resolved https://github.com/FelipeSchreiber/BregmanClustering.git to commit 413a49e0e0435d4a72f4f77b143b0c262c32bbbe\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch_geometric\n",
            "  Using cached torch_geometric-2.3.0-py3-none-any.whl\n",
            "Collecting rpy2==3.5.1\n",
            "  Using cached rpy2-3.5.1-cp39-cp39-linux_x86_64.whl\n",
            "Collecting cffi>=1.10.0\n",
            "  Using cached cffi-1.15.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (441 kB)\n",
            "Collecting tzlocal\n",
            "  Using cached tzlocal-4.3-py3-none-any.whl (20 kB)\n",
            "Collecting pytz\n",
            "  Using cached pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
            "Collecting jinja2\n",
            "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "Collecting pyparsing\n",
            "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "Collecting scipy\n",
            "  Using cached scipy-1.10.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "Collecting psutil>=5.8.0\n",
            "  Using cached psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "Collecting scikit-learn\n",
            "  Using cached scikit_learn-1.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "Collecting requests\n",
            "  Using cached requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "Collecting numpy\n",
            "  Using cached numpy-1.24.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "Collecting tqdm\n",
            "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
            "Collecting pycparser\n",
            "  Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
            "Collecting MarkupSafe>=2.0\n",
            "  Using cached MarkupSafe-2.1.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Using cached urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
            "Collecting idna<4,>=2.5\n",
            "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
            "Collecting certifi>=2017.4.17\n",
            "  Using cached certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
            "Collecting charset-normalizer<4,>=2\n",
            "  Using cached charset_normalizer-3.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
            "Collecting joblib>=1.1.1\n",
            "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting pytz-deprecation-shim\n",
            "  Using cached pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tzdata\n",
            "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "Building wheels for collected packages: bregClust\n",
            "  Building wheel for bregClust (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bregClust: filename=bregClust-1.0-py3-none-any.whl size=17907 sha256=3c2ffce1885b8e65ec97d9c4dcce7dd576246e430d96eee8ef3f61eef88a7355\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zy_bwh98/wheels/6f/8f/ab/2faa84d8b9fad58989d72cda12225f6191888313b2d42f6ad5\n",
            "Successfully built bregClust\n",
            "Installing collected packages: pytz, urllib3, tzdata, tqdm, threadpoolctl, pyparsing, pycparser, psutil, numpy, MarkupSafe, joblib, idna, charset-normalizer, certifi, scipy, requests, pytz-deprecation-shim, jinja2, cffi, tzlocal, scikit-learn, torch_geometric, rpy2, bregClust\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2023.3\n",
            "    Uninstalling pytz-2023.3:\n",
            "      Successfully uninstalled pytz-2023.3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.15\n",
            "    Uninstalling urllib3-1.26.15:\n",
            "      Successfully uninstalled urllib3-1.26.15\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2023.3\n",
            "    Uninstalling tzdata-2023.3:\n",
            "      Successfully uninstalled tzdata-2023.3\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.65.0\n",
            "    Uninstalling tqdm-4.65.0:\n",
            "      Successfully uninstalled tqdm-4.65.0\n",
            "  Attempting uninstall: threadpoolctl\n",
            "    Found existing installation: threadpoolctl 3.1.0\n",
            "    Uninstalling threadpoolctl-3.1.0:\n",
            "      Successfully uninstalled threadpoolctl-3.1.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: pycparser\n",
            "    Found existing installation: pycparser 2.21\n",
            "    Uninstalling pycparser-2.21:\n",
            "      Successfully uninstalled pycparser-2.21\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.9.4\n",
            "    Uninstalling psutil-5.9.4:\n",
            "      Successfully uninstalled psutil-5.9.4\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.24.2\n",
            "    Uninstalling numpy-1.24.2:\n",
            "      Successfully uninstalled numpy-1.24.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.1.2\n",
            "    Uninstalling MarkupSafe-2.1.2:\n",
            "      Successfully uninstalled MarkupSafe-2.1.2\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.2.0\n",
            "    Uninstalling joblib-1.2.0:\n",
            "      Successfully uninstalled joblib-1.2.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.4\n",
            "    Uninstalling idna-3.4:\n",
            "      Successfully uninstalled idna-3.4\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.1.0\n",
            "    Uninstalling charset-normalizer-3.1.0:\n",
            "      Successfully uninstalled charset-normalizer-3.1.0\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2022.12.7\n",
            "    Uninstalling certifi-2022.12.7:\n",
            "      Successfully uninstalled certifi-2022.12.7\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.10.1\n",
            "    Uninstalling scipy-1.10.1:\n",
            "      Successfully uninstalled scipy-1.10.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.28.2\n",
            "    Uninstalling requests-2.28.2:\n",
            "      Successfully uninstalled requests-2.28.2\n",
            "  Attempting uninstall: pytz-deprecation-shim\n",
            "    Found existing installation: pytz-deprecation-shim 0.1.0.post0\n",
            "    Uninstalling pytz-deprecation-shim-0.1.0.post0:\n",
            "      Successfully uninstalled pytz-deprecation-shim-0.1.0.post0\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.2\n",
            "    Uninstalling Jinja2-3.1.2:\n",
            "      Successfully uninstalled Jinja2-3.1.2\n",
            "  Attempting uninstall: cffi\n",
            "    Found existing installation: cffi 1.15.1\n",
            "    Uninstalling cffi-1.15.1:\n",
            "      Successfully uninstalled cffi-1.15.1\n",
            "  Attempting uninstall: tzlocal\n",
            "    Found existing installation: tzlocal 4.3\n",
            "    Uninstalling tzlocal-4.3:\n",
            "      Successfully uninstalled tzlocal-4.3\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: torch_geometric\n",
            "    Found existing installation: torch-geometric 2.3.0\n",
            "    Uninstalling torch-geometric-2.3.0:\n",
            "      Successfully uninstalled torch-geometric-2.3.0\n",
            "  Attempting uninstall: rpy2\n",
            "    Found existing installation: rpy2 3.5.1\n",
            "    Uninstalling rpy2-3.5.1:\n",
            "      Successfully uninstalled rpy2-3.5.1\n",
            "  Attempting uninstall: bregClust\n",
            "    Found existing installation: bregClust 1.0\n",
            "    Uninstalling bregClust-1.0:\n",
            "      Successfully uninstalled bregClust-1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.24.2 which is incompatible.\n",
            "pandas-profiling 3.2.0 requires joblib~=1.1.0, but you have joblib 1.2.0 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-2.1.2 bregClust-1.0 certifi-2022.12.7 cffi-1.15.1 charset-normalizer-3.1.0 idna-3.4 jinja2-3.1.2 joblib-1.2.0 numpy-1.24.2 psutil-5.9.4 pycparser-2.21 pyparsing-3.0.9 pytz-2023.3 pytz-deprecation-shim-0.1.0.post0 requests-2.28.2 rpy2-3.5.1 scikit-learn-1.2.2 scipy-1.10.1 threadpoolctl-3.1.0 torch_geometric-2.3.0 tqdm-4.65.0 tzdata-2023.3 tzlocal-4.3 urllib3-1.26.15\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall git+https://github.com/FelipeSchreiber/BregmanClustering.git\n",
        "!chmod 777 /usr/local/lib/python3.9/dist-packages/BregmanTests/install_algos.sh"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from BregmanTests.install_algorithms import main as install_env\n",
        "install_env()"
      ],
      "metadata": {
        "id": "E-wm63rs1vPg",
        "outputId": "017509a9-f232-4270-ee4d-4f910453c2d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 744
        }
      },
      "id": "E-wm63rs1vPg",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading packages from github...\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-25defe9664bc>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mBregmanTests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstall_algorithms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minstall_env\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minstall_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/BregmanTests/install_algorithms.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"{bash_path}\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mmodify_csbm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./CSBM/Python/functions.py\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mmodify_att_sbm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_att_sbm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Installing R packages...\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mutils\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utils'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/BregmanTests/install_algorithms.py\u001b[0m in \u001b[0;36mmodify_att_sbm\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodify_att_sbm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileinput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{line.replace(\")\",\",kmeansinit)\")}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/fileinput.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filelineno\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/fileinput.py\u001b[0m in \u001b[0;36m_readline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    341\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                 \u001b[0;31m# The next few lines may raise OSError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backupfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backupfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/usr/local/lib/python3.9/dist-packages/BregmanTestsAttributedSBM/FitAttribute.R' -> '/usr/local/lib/python3.9/dist-packages/BregmanTestsAttributedSBM/FitAttribute.R.bak'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ff28023",
      "metadata": {
        "id": "9ff28023"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "from BregmanTests.WSBM import *\n",
        "import BregmanTests\n",
        "from copy import deepcopy\n",
        "from sklearn.metrics import adjusted_rand_score, calinski_harabasz_score, normalized_mutual_info_score, accuracy_score\n",
        "#from signet.cluster import Cluster\n",
        "from sklearn.manifold import spectral_embedding,SpectralEmbedding\n",
        "import scipy.sparse as ss\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.metrics.pairwise import pairwise_kernels\n",
        "import sys\n",
        "from CSBM.Python.functions import *\n",
        "import os\n",
        "import warnings\n",
        "from BregmanClustering import models\n",
        "from BregmanClustering.models import SoftBregmanNodeAttributeGraphClustering as VEMbreg\n",
        "from BregmanClusteringTorch.torch_models import SoftBregmanClusteringTorch as torchBreg\n",
        "import rpy2.robjects as robjects\n",
        "import subprocess\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31fa08e4",
      "metadata": {
        "id": "31fa08e4"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Fri Feb 17 17:08:00 2023\n",
        "\n",
        "@author: maximilien, Felipe Schreiber\n",
        "\"\"\"\n",
        "from tqdm import tqdm\n",
        "\n",
        "SIZE_TITLE = 24\n",
        "SIZE_LABELS = 24\n",
        "SIZE_TICKS = 18\n",
        "SIZE_LEGEND = 18\n",
        "\n",
        "def unitRootCoordinates( d = 2, r=1 ):\n",
        "    coordinates = []\n",
        "    for k in range( d ):\n",
        "        coordinates.append( [ r*np.cos(2*k*np.pi / d ), r*np.sin( 2*k*np.pi / d ) ])\n",
        "    return coordinates\n",
        "\n",
        "def generateData( sizes, p, mu ):\n",
        "    n = sum( sizes )\n",
        "    n_clusters = len( sizes )\n",
        "    d = len( mu[0] )\n",
        "    \n",
        "    labels_true = [ ]\n",
        "    for k in range( n_clusters ):\n",
        "        labels_true += [ k for i in range( sizes[ k ] ) ]\n",
        "    labels_true = np.asarray( labels_true, dtype = int )\n",
        "\n",
        "    G = nx.stochastic_block_model( sizes, p )\n",
        "    X = nx.adjacency_matrix( G ).todense()\n",
        "    \n",
        "    Y = np.zeros( ( n,d ) )\n",
        "    for i in range( n ):\n",
        "        Y[i,:] = np.random.normal( loc = mu[ labels_true[i] ] )\n",
        "    return np.asarray(X), Y, labels_true\n",
        "\n",
        "\n",
        "def plotting( x, curves, labels, xticks,\n",
        "             curves_std = None,\n",
        "             legendTitle = '', figTitle = '',\n",
        "             xlabel = 'a', ylabel = 'ARI',\n",
        "             saveFig = False, fileName = 'fig.eps'):\n",
        "    \n",
        "    if len( curves ) != len( labels ):\n",
        "        raise TypeError( 'The number of labels is different from the number of curves' )\n",
        "    \n",
        "    if curves_std == None:\n",
        "        for i in range( len( labels) ):\n",
        "            plt.plot( x, curves[i], label = labels[i])\n",
        "    else:\n",
        "        for i in range( len( labels) ):\n",
        "            plt.errorbar( x, curves[ i ], yerr = curves_std[ i ], linestyle = '-.', label = labels[ i ] )\n",
        "\n",
        "    \n",
        "    legend = plt.legend( title = legendTitle, loc=4,  fancybox=True, fontsize= SIZE_LEGEND )\n",
        "    plt.setp( legend.get_title(),fontsize= SIZE_LEGEND )\n",
        "    plt.xlabel( xlabel, fontsize = SIZE_LABELS )\n",
        "    plt.ylabel( ylabel, fontsize = SIZE_LABELS )\n",
        "    plt.xticks( xticks, fontsize = SIZE_TICKS )\n",
        "    plt.yticks( fontsize = SIZE_TICKS )\n",
        "    plt.title( figTitle, fontsize = SIZE_TITLE )\n",
        "    if saveFig:\n",
        "        plt.savefig( fileName, format = 'eps', bbox_inches = 'tight' )\n",
        "\n",
        "#Somehow some errors message sometimes arises such as \n",
        "#RuntimeWarning: divide by zero encountered in log\n",
        "#But this shouldn be a problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0dbd1e34",
      "metadata": {
        "id": "0dbd1e34"
      },
      "outputs": [],
      "source": [
        "c = 3\n",
        "n = 100\n",
        "N = c*n\n",
        "delta = 10\n",
        "d = 2\n",
        "dim = c*d\n",
        "P = np.array([[0.8, 0.2, 0.3],[0.2, 0.7, 0.4],[0.3, 0.4, 0.6]])\n",
        "true_labels = [0]*n + [1]*n + [2]*n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2ad4db3",
      "metadata": {
        "id": "d2ad4db3"
      },
      "outputs": [],
      "source": [
        "X,Y = BregmanBenchmark(P,[n]*c,1,10,dims=2,weight_variance=0.01,att_variance=0.1,\\\n",
        "                       weight_distribution=\"logistic\",attributes_distribution=\"logistic\").generate_benchmark_WSBM()\n",
        "A = (X != 0).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e505252",
      "metadata": {
        "id": "8e505252"
      },
      "outputs": [],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "360bfa70",
      "metadata": {
        "id": "360bfa70"
      },
      "outputs": [],
      "source": [
        "plt.scatter(Y[:,0],Y[:,1],c=true_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d13df589",
      "metadata": {
        "id": "d13df589"
      },
      "outputs": [],
      "source": [
        "def get_spectral_decomposition(A,k):\n",
        "    if (A<0).any():\n",
        "        A = pairwise_kernels(A,metric='rbf')\n",
        "    U = SpectralEmbedding(n_components=k,affinity=\"precomputed\").fit_transform(A)\n",
        "    return U\n",
        "def spectral(A,k):\n",
        "    U = get_spectral_decomposition(A,k)\n",
        "    return GaussianMixture(n_components=k).fit_predict(U.real)\n",
        "pred_labels = spectral(X.copy(),c)\n",
        "print(adjusted_rand_score(true_labels, pred_labels),normalized_mutual_info_score(true_labels, pred_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "189cbdb7",
      "metadata": {
        "id": "189cbdb7"
      },
      "outputs": [],
      "source": [
        "pred_labels = GaussianMixture(n_components=c).fit_predict(Y.copy())\n",
        "print(adjusted_rand_score(true_labels, pred_labels),normalized_mutual_info_score(true_labels, pred_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5f446f8",
      "metadata": {
        "id": "e5f446f8"
      },
      "outputs": [],
      "source": [
        "model = torchBreg(n_clusters=c,normalize_=True,thresholding=True)\n",
        "model.fit(A, Y)\n",
        "z_pred_both = model.predict(A,Y)\n",
        "print(adjusted_rand_score(true_labels, z_pred_both),normalized_mutual_info_score(true_labels, z_pred_both))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e151220",
      "metadata": {
        "id": "9e151220",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "n_average = 1\n",
        "n = 300\n",
        "n_clusters = 2\n",
        "d = 1\n",
        "sizes = [ n // n_clusters ]*np.ones( n_clusters, dtype = int )\n",
        "\n",
        "b = 5\n",
        "pout = b * np.log( n ) / n\n",
        "\n",
        "a_range = [ 5,7,9,11,13,15 ]\n",
        "r_range = [ 0,1,2,3,4,5 ]\n",
        "# a_range = [ 5,7,9]\n",
        "# r_range = [ 0,1,2]\n",
        "\n",
        "stats = {\"varying\":[],\"a\":[],\"r\":[],\"agreed\":[],\"ARI_chernoff\":[],\"ARI_AIC\":[],\"ARI_ORACLE\":[]}\n",
        "\n",
        "for varying in [\"attributes\",\"graph\"]:\n",
        "# varying = 'attributes'\n",
        "# #varying = 'graph'\n",
        "\n",
        "    aris_attributes_mean = [ ]\n",
        "    aris_graph_mean = [ ]\n",
        "    aris_both_mean = [ ]\n",
        "    aris_attSBM_mean = [ ]\n",
        "    aris_IR_sLS_mean = [ ]\n",
        "    aris_IR_LS_mean = [ ]\n",
        "    aris_both2_mean = [ ]\n",
        "    aris_oracle_mean = [ ]\n",
        "\n",
        "    aris_attributes_std = [ ]\n",
        "    aris_graph_std = [ ]\n",
        "    aris_both_std = [ ]\n",
        "    aris_attSBM_std = [ ]\n",
        "    aris_IR_sLS_std = [ ]\n",
        "    aris_IR_LS_std = [ ]\n",
        "    aris_both2_std = [ ]\n",
        "    aris_oracle_std = [ ]\n",
        "\n",
        "    if varying == 'graph':\n",
        "        loop = tqdm( range( len( a_range ) ) )\n",
        "    else:\n",
        "        loop = tqdm( range( len( r_range ) ) )\n",
        "\n",
        "    for dummy in loop:\n",
        "        if varying == 'graph':\n",
        "            a = a_range[ dummy ]\n",
        "            r = 1\n",
        "        elif varying == 'attributes':\n",
        "            a = 8\n",
        "            r = r_range[ dummy ]\n",
        "        mu = np.array([ [r], [-r] ])\n",
        "        #print(mu.shape)\n",
        "        #mu = unitRootCoordinates( d=2, r=r )\n",
        "\n",
        "        pin = a * np.log( n ) / n\n",
        "        p = (pin- pout) * np.eye( n_clusters ) + pout * np.ones( (n_clusters, n_clusters) )\n",
        "\n",
        "        aris_attributes = [ ]\n",
        "        aris_graph = [ ]\n",
        "        aris_both = [ ]\n",
        "        aris_attSBM = [ ]\n",
        "        aris_IR_sLS  = [ ]\n",
        "        aris_IR_LS = [ ]\n",
        "        aris_both2 = [ ]\n",
        "        aris_oracle = [ ]\n",
        "        \n",
        "        path_ = path+f\"a/{a}/r/{r}/\"\n",
        "        if not os.path.exists(path_):\n",
        "            os.makedirs(path_)\n",
        "\n",
        "        total = 0\n",
        "        for trial in range( n_average ):\n",
        "            ( X, Y, z_true ) = generateData( sizes, p, mu )\n",
        "            model = models.BregmanNodeAttributeGraphClustering( n_clusters = n_clusters, initializer=\"chernoff\")\n",
        "            ## For comparison purposes, the initialization is the same for IR-sLS, IR-LS and ours    \n",
        "            model.initialize(X,Y)\n",
        "            model.assignInitialLabels( X, Y )\n",
        "            z_init = model.predicted_memberships\n",
        "            chernoff_init_graph = model.graph_init\n",
        "            chernoff_graph_labels = model.memberships_from_graph\n",
        "            chernoff_att_labels = model.memberships_from_attributes\n",
        "\n",
        "            with open(f'{path_}att_{trial}.npy', 'wb') as g:\n",
        "                np.save(g, Y)\n",
        "            with open(f'{path_}net_{trial}.npy', 'wb') as g:\n",
        "                np.save(g, X)\n",
        "            with open(f'{path_}z_init_{trial}.npy', 'wb') as g:\n",
        "                np.save(g, convertZ(z_init)+1)\n",
        "\n",
        "            model.fit( X, Y )\n",
        "            z_pred_both = model.predict( X, Y )\n",
        "            z_pred_graph = models.frommembershipMatriceToVector( chernoff_graph_labels )\n",
        "            z_pred_attributes = models.frommembershipMatriceToVector( chernoff_att_labels )\n",
        "            \n",
        "            if chernoff_init_graph == model.AIC_initializer(X,Y).graph_init:\n",
        "                total += 1\n",
        "            \n",
        "            ## Warm start\n",
        "            if model.graph_init:\n",
        "                model.fit( X, Y, chernoff_graph_labels)\n",
        "            else:\n",
        "                model.fit(X, Y, chernoff_att_labels)\n",
        "            \n",
        "            model2 = torchBreg(n_clusters=n_clusters, normalize_=True, thresholding=True)\n",
        "            z_pred_both2 = model2.fit(X,Y).predict( X, Y )\n",
        "            \n",
        "            IR_sLS_pred = iter_csbm(X,Y,z_init,n_clusters)\n",
        "            IR_LS_pred = iter_csbm2(X,Y,z_init,n_clusters)\n",
        "                \n",
        "            subprocess.call([\"/usr/bin/Rscript\",\"--vanilla\",\"./run_AttSBM.r\",\\\n",
        "                            f'{path_}att_{trial}.npy',\\\n",
        "                            f'{path_}net_{trial}.npy',\\\n",
        "                            f'{path_}z_init_{trial}.npy'])\n",
        "            # r_code = f\"\"\"\n",
        "            # source(\"run_AttSBM.r\")\n",
        "            # run_AttSBM({path_}att_{trial}.npy,{path_}net_{trial}.npy,{path_}z_init_{trial}.npy)\"\"\"\n",
        "            # print(r_code)\n",
        "            # robjects.r(r_code)\n",
        "\n",
        "            attSBMPred = np.load(\"predict.npy\")\n",
        "\n",
        "            aris_attributes.append( adjusted_rand_score( z_true, z_pred_attributes ) )\n",
        "            aris_graph.append( adjusted_rand_score( z_true, z_pred_graph ) )\n",
        "            aris_both.append( adjusted_rand_score( z_true, z_pred_both ) )\n",
        "            aris_attSBM.append( adjusted_rand_score( z_true, attSBMPred ) )\n",
        "            aris_IR_sLS.append( adjusted_rand_score( z_true, IR_sLS_pred ) )\n",
        "            aris_IR_LS.append( adjusted_rand_score( z_true, IR_LS_pred ) )\n",
        "            aris_both2.append( adjusted_rand_score( z_true, z_pred_both2 ))\n",
        "            \n",
        "            if chernoff_init_graph != model.AIC_initializer(X,Y).graph_init:\n",
        "                ## both initializations were done\n",
        "                aris_oracle.append( max(aris_both[-1],aris_both2[-1]))\n",
        "            elif chernoff_init_graph:\n",
        "                z_pred_att_init = model.fit(X,Y,chernoff_att_labels).predict(X,Y)\n",
        "                ari_att_init = adjusted_rand_score( z_true, z_pred_att_init)\n",
        "                aris_oracle.append( max(aris_both[-1], ari_att_init))\n",
        "            elif not chernoff_init_graph:\n",
        "                z_pred_graph_init = model.fit(X,Y,chernoff_graph_labels).predict(X,Y)\n",
        "                ari_graph_init = adjusted_rand_score( z_true, z_pred_graph_init)\n",
        "                aris_oracle.append( max(aris_both[-1], ari_graph_init))\n",
        "                \n",
        "        aris_attributes_mean.append( np.mean( aris_attributes ) )\n",
        "        aris_graph_mean.append( np.mean( aris_graph ) )\n",
        "        aris_both_mean.append( np.mean( aris_both ) )\n",
        "        aris_attSBM_mean.append( np.mean( aris_attSBM ) )\n",
        "        aris_IR_sLS_mean.append( np.mean( aris_IR_sLS ) )\n",
        "        aris_IR_LS_mean.append( np.mean( aris_IR_LS ) )\n",
        "        aris_both2_mean.append( np.mean( aris_both2) )\n",
        "        aris_oracle_mean.append( np.mean( aris_oracle) )\n",
        "        \n",
        "        aris_attributes_std.append( np.std( aris_attributes ) )\n",
        "        aris_graph_std.append( np.std( aris_graph ) )\n",
        "        aris_both_std.append( np.std( aris_both ) )\n",
        "        aris_attSBM_std.append( np.std( aris_attSBM ) )\n",
        "        aris_IR_sLS_std.append( np.std( aris_IR_sLS ) )\n",
        "        aris_IR_LS_std.append( np.std( aris_IR_LS ) )\n",
        "        aris_both2_std.append( np.std( aris_both2 ) )\n",
        "        aris_oracle_std.append( np.std( aris_oracle) )\n",
        "        \n",
        "        stats[\"varying\"].append(varying)\n",
        "        stats[\"a\"].append(a)\n",
        "        stats[\"r\"].append(r)\n",
        "        stats[\"agreed\"].append(total/n_average)\n",
        "        stats[\"ARI_chernoff\"].append(aris_both_mean[-1])\n",
        "        stats[\"ARI_AIC\"].append(aris_both2_mean[-1])\n",
        "        stats[\"ARI_ORACLE\"].append(aris_oracle_mean[-1])\n",
        "        \n",
        "    curves = [ aris_attributes_mean, aris_graph_mean,\\\n",
        "              aris_both_mean , aris_attSBM_mean, aris_IR_sLS_mean,\\\n",
        "              aris_IR_LS_mean, aris_both2_mean]\n",
        "\n",
        "    curves_std = [ aris_attributes_std, aris_graph_std,\\\n",
        "                  aris_both_std , aris_attSBM_std, aris_IR_sLS_std,\\\n",
        "                  aris_IR_LS_std, aris_both2_std]\n",
        "\n",
        "    labels = [ 'attributes', 'graph', 'both' , 'attSBM', 'IR_sLS', 'IR_LS', \"VEMbreg\"]\n",
        "    saveFig = True\n",
        "    if varying == 'graph':    \n",
        "        fileName = 'N_' + str(n) + '_K_' + str(n_clusters) + '_b_' + str(b) + '_r_' + str(r) +  '_nAverage' + str(n_average) + '.eps'\n",
        "        plotting( a_range, curves, labels, curves_std = curves_std, xticks = a_range, xlabel = 'a', saveFig = saveFig, fileName = fileName )\n",
        "        plt.close()\n",
        "    elif varying == 'attributes':\n",
        "        fileName = 'N_' + str(n) + '_K_' + str(n_clusters) + '_a_' + str(a) + '_b_' + str(b) +  '_nAverage_' + str(n_average) + '.eps'\n",
        "        plotting( r_range, curves, labels, curves_std = curves_std, xticks = r_range, xlabel = 'r', saveFig = saveFig, fileName = fileName )\n",
        "        plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ef9402f",
      "metadata": {
        "id": "0ef9402f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame.from_dict(stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ba58beb",
      "metadata": {
        "id": "2ba58beb"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}